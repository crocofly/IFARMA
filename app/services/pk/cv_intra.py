"""
services/pk/cv_intra.py ‚Äî –ú–æ–¥—É–ª—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è CVintra.

–î–í–ê –ú–ï–¢–û–î–ê:
1. –ü–æ–∏—Å–∫ –≥–æ—Ç–æ–≤–æ–≥–æ CVintra –∏–∑ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã (PubMed, FDA Guidance)
2. –†–∞—Å—á—ë—Ç CVintra –∏–∑ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö 90% CI

–ü–†–ò–û–†–ò–¢–ï–¢ (–ò–ó–ú–ï–ù–Å–ù ‚Äî PubMed –ü–ï–†–í–´–ú!):
1. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–µ—Ä–µ–¥–∞–ª --cv-intra ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º
2. PubMed: —Å—Ç–∞—Ç—å—è —Å 90% CI –∏–∑ BE-–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è ‚Üí —Ä–∞—Å—á—ë—Ç CVintra
3. PubMed: —Å—Ç–∞—Ç—å—è —Å –ø—Ä—è–º—ã–º CVintra –∏–∑ BE-–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
4. FDA/EMA BE Guidance Document ‚Üí CVintra (–ù–û: 30% = –ø–æ—Ä–æ–≥, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
5. –®–∏—Ä–æ–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É
6. Default 30% (–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)

–í–ê–ñ–ù–û: –ü–æ–∏—Å–∫ –≤–µ–¥—ë—Ç—Å—è –ø–æ –ë–ê–ó–û–í–û–ú–£ –ú–ù–ù –±–µ–∑ —Å–æ–ª–∏!
    "—Ç–µ–Ω–æ—Ñ–æ–≤–∏—Ä–∞ –∞–ª–∞—Ñ–µ–Ω–∞–º–∏–¥ —Ñ—É–º–∞—Ä–∞—Ç" ‚Üí "—Ç–µ–Ω–æ—Ñ–æ–≤–∏—Ä–∞ –∞–ª–∞—Ñ–µ–Ω–∞–º–∏–¥"
    "tenofovir alafenamide fumarate" ‚Üí "tenofovir alafenamide"

–§–û–†–ú–£–õ–ê –†–ê–°–ß–Å–¢–ê CVintra –ò–ó 90% CI:
    œÉ¬≤w = MSE (—Å—Ä–µ–¥–Ω–∏–π –∫–≤–∞–¥—Ä–∞—Ç –æ—à–∏–±–∫–∏ –∏–∑ ANOVA –ª–æ–≥-–¥–∞–Ω–Ω—ã—Ö)
    CVintra = ‚àö(exp(œÉ¬≤w) ‚àí 1) √ó 100%
    –≠–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ —Ñ—É–Ω–∫—Ü–∏–∏ CVfromCI() –∏–∑ R-–ø–∞–∫–µ—Ç–∞ PowerTOST.

–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï v2 (_extract_cv_from_text):
    Sentence-boundary –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–º–µ—Å—Ç–æ regex-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.
    –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è inter-subject / between-subject CV.
    –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è intra-subject + Cmax.
"""

import math
import os
import re
import requests
from typing import Optional, Tuple, Dict, List
from scipy import stats
from dataclasses import dataclass


YANDEX_GEN_SEARCH_URL = "https://searchapi.api.cloud.yandex.net/v2/gen/search"


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ú–ù–ù ‚Äî –£–ë–ò–†–ê–ï–ú –°–û–õ–¨, –ü–ï–†–ï–í–û–î–ò–ú ru‚Üíen
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ inn_utils (–∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫)
try:
    from app.utils.inn_utils import normalize_inn, strip_salt_ru, strip_salt_en, resolve_inn_en
    _HAS_INN_UTILS = True
except ImportError:
    try:
        from inn_utils import normalize_inn, strip_salt_ru, strip_salt_en, resolve_inn_en
        _HAS_INN_UTILS = True
    except ImportError:
        _HAS_INN_UTILS = False


# Fallback –µ—Å–ª–∏ inn_utils –Ω–µ –Ω–∞–π–¥–µ–Ω
if not _HAS_INN_UTILS:
    import re as _re
    _SALT_EN = [
        "fumarate", "hemifumarate", "hydrochloride", "dihydrochloride",
        "maleate", "mesylate", "besylate", "tartrate", "succinate",
        "citrate", "phosphate", "sulfate", "acetate", "bromide",
        "chloride", "tosylate", "sodium", "potassium", "calcium",
        "magnesium", "monohydrate", "dihydrate",
    ]
    _SALT_RU = [
        "—Ñ—É–º–∞—Ä–∞—Ç", "–≥–∏–¥—Ä–æ—Ö–ª–æ—Ä–∏–¥", "–º–∞–ª–µ–∞—Ç", "–º–µ–∑–∏–ª–∞—Ç", "–±–µ–∑–∏–ª–∞—Ç",
        "—Ç–∞—Ä—Ç—Ä–∞—Ç", "—Å—É–∫—Ü–∏–Ω–∞—Ç", "—Ü–∏—Ç—Ä–∞—Ç", "—Ñ–æ—Å—Ñ–∞—Ç", "—Å—É–ª—å—Ñ–∞—Ç",
        "–∞—Ü–µ—Ç–∞—Ç", "–±—Ä–æ–º–∏–¥", "—Ö–ª–æ—Ä–∏–¥", "—Ç–æ–∑–∏–ª–∞—Ç", "–Ω–∞—Ç—Ä–∏—è",
        "–∫–∞–ª–∏—è", "–∫–∞–ª—å—Ü–∏—è", "–º–∞–≥–Ω–∏—è", "–º–æ–Ω–æ–≥–∏–¥—Ä–∞—Ç", "–¥–∏–≥–∏–¥—Ä–∞—Ç",
    ]
    def strip_salt_en(s):
        r = s.strip().lower()
        for salt in sorted(_SALT_EN, key=len, reverse=True):
            if r.endswith(salt): r = r[:-len(salt)].strip()
        return r or s.strip()
    def strip_salt_ru(s):
        r = s.strip().lower()
        for salt in sorted(_SALT_RU, key=len, reverse=True):
            if r.endswith(salt): r = r[:-len(salt)].strip()
        return r or s.strip()
    def normalize_inn(inn_ru, inn_en=None):
        return strip_salt_ru(inn_ru), strip_salt_en(inn_en) if inn_en else ""
    def resolve_inn_en(inn_ru):
        return ""  # –±–µ–∑ —Å–ª–æ–≤–∞—Ä—è –Ω–µ –º–æ–∂–µ–º –ø–µ—Ä–µ–≤–µ—Å—Ç–∏


@dataclass
class CVintraResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è CVintra."""
    cv_intra: float
    source: str
    source_detail: str
    confidence: str
    method: str
    ci_data: Optional[Dict] = None


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –†–ê–°–ß–Å–¢ CVintra –ò–ó 90% CI
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def cv_from_ci(
    lower: float, upper: float, n: int,
    design: str = "2x2x2", alpha: float = 0.05,
) -> float:
    """
    CVintra –∏–∑ 90% CI. –≠–∫–≤–∏–≤–∞–ª–µ–Ω—Ç CVfromCI() –∏–∑ PowerTOST.
    """
    if lower > 2:
        lower = lower / 100
    if upper > 2:
        upper = upper / 100
    if lower <= 0 or upper <= 0 or lower >= upper:
        raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã CI: [{lower}, {upper}]")
    if n < 4:
        raise ValueError(f"–°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–æ–±—Ä–æ–≤–æ–ª—å—Ü–µ–≤: n={n}")

    df = _get_df(n, design)
    halfwidth = (math.log(upper) - math.log(lower)) / 2
    t_val = stats.t.ppf(1 - alpha, df)
    mse = (halfwidth ** 2) * n / (2 * t_val ** 2)
    cv = math.sqrt(math.exp(mse) - 1) * 100
    return round(cv, 1)


def _get_df(n: int, design: str) -> int:
    if design in ("2x2x2", "2x2"):
        return n - 2
    elif design in ("2x2x4", "2x4x4"):
        return 3 * (n // 2) - 3
    elif design in ("2x2x3",):
        return 2 * (n // 2) - 2
    elif design == "parallel":
        return n - 2
    else:
        return n - 2


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ü–û–ò–°–ö CVintra
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def search_cv_intra(
    inn_en: str,
    inn_ru: str = "",
    ref_drug_name: str = "",
    folder_id: Optional[str] = None,
    api_key: Optional[str] = None,
) -> CVintraResult:
    """
    –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–æ–∏—Å–∫ CVintra.

    –í–ê–ñ–ù–û:
    - ref_drug_name –ò–ì–ù–û–†–ò–†–£–ï–¢–°–Ø. CVintra ‚Äî —Å–≤–æ–π—Å—Ç–≤–æ –ú–ù–ù, –Ω–µ –±—Ä–µ–Ω–¥–∞.
    - –ï—Å–ª–∏ inn_en –ø—É—Å—Ç–æ–π ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º –∏–∑ inn_ru —á–µ—Ä–µ–∑ —Å–ª–æ–≤–∞—Ä—å.
    - –ü–æ–∏—Å–∫ –ø–æ –±–∞–∑–æ–≤–æ–º—É –ú–ù–ù (–±–µ–∑ —Å–æ–ª–∏), –∑–∞—Ç–µ–º –ø–æ –ø–æ–ª–Ω–æ–º—É.

    –ü–æ—Ä—è–¥–æ–∫:
    1. PubMed CI ‚Üí —Ä–∞—Å—á—ë—Ç CVintra (—Å–∞–º—ã–π –Ω–∞–¥—ë–∂–Ω—ã–π)
    2. PubMed direct CVintra
    3. FDA BE Guidance
    4. –®–∏—Ä–æ–∫–∏–π –∏–Ω—Ç–µ—Ä–Ω–µ—Ç
    5. –ü–æ–≤—Ç–æ—Ä 1-4 —Å –ø–æ–ª–Ω—ã–º –ú–ù–ù (—Å —Å–æ–ª—å—é)
    6. Default = 30%
    """
    folder_id = folder_id or os.getenv("YANDEX_FOLDER_ID", "")
    api_key = api_key or os.getenv("YANDEX_API_KEY", "")

    if not folder_id or not api_key:
        return _default_result()

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø: —É–±–∏—Ä–∞–µ–º —Å–æ–ª—å + –∞–≤—Ç–æ-–ø–µ—Ä–µ–≤–æ–¥ ru‚Üíen
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    inn_ru_base, inn_en_base = normalize_inn(inn_ru, inn_en if inn_en else None)

    # –ï—Å–ª–∏ normalize_inn –Ω–µ –Ω–∞—à—ë–ª –ø–µ—Ä–µ–≤–æ–¥ ‚Äî –ø—Ä–æ–±—É–µ–º resolve_inn_en
    if not inn_en_base and inn_ru:
        inn_en_base = resolve_inn_en(inn_ru)

    # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Ä–º–∏–Ω ‚Äî –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –±–µ–∑ —Å–æ–ª–∏
    search_base = inn_en_base or (strip_salt_en(inn_en) if inn_en else "") or inn_ru_base or inn_ru
    # –ü–æ–ª–Ω—ã–π —Ç–µ—Ä–º–∏–Ω (—Å —Å–æ–ª—å—é) ‚Äî fallback
    search_full = inn_en or inn_ru

    if search_base.lower() != search_full.lower():
        print(f"  –ú–ù–ù –¥–ª—è –ø–æ–∏—Å–∫–∞: '{search_base}' (–±–∞–∑–æ–≤—ã–π), '{search_full}' (–ø–æ–ª–Ω—ã–π)")
    else:
        print(f"  –ú–ù–ù –¥–ª—è –ø–æ–∏—Å–∫–∞: '{search_base}'")

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –†–ê–£–ù–î 1: –±–∞–∑–æ–≤—ã–π –ú–ù–ù (–±–µ–∑ —Å–æ–ª–∏)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    result = _search_all_sources(search_base, folder_id, api_key)
    if result:
        return result

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –†–ê–£–ù–î 2: –ø–æ–ª–Ω—ã–π –ú–ù–ù (—Å —Å–æ–ª—å—é)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    if search_full.lower() != search_base.lower():
        print(f"  ‚Ü≥ –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ '{search_base}'. –ü—Ä–æ–±—É–µ–º '{search_full}'...")
        result = _search_all_sources(search_full, folder_id, api_key)
        if result:
            return result

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –†–ê–£–ù–î 3: —Ä—É—Å—Å–∫–∏–π –ú–ù–ù (fallback)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    for term in _unique([inn_ru_base, inn_ru]):
        if term and term.lower() not in (search_base.lower(), search_full.lower()):
            print(f"  ‚Ü≥ –ü—Ä–æ–±—É–µ–º —Ä—É—Å—Å–∫–∏–π –ú–ù–ù: '{term}'...")
            result = _search_all_sources(term, folder_id, api_key)
            if result:
                return result

    return _default_result()


def _search_all_sources(
    term: str, folder_id: str, api_key: str,
) -> Optional[CVintraResult]:
    """–ü–æ–∏—Å–∫ CVintra –ø–æ –æ–¥–Ω–æ–º—É —Ç–µ—Ä–º–∏–Ω—É –≤–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö."""
    # 1. PubMed CI ‚Üí —Ä–∞—Å—á—ë—Ç
    result = _search_pubmed_ci(term, folder_id, api_key)
    if result:
        return result

    # 2. PubMed direct
    result = _search_pubmed_direct(term, folder_id, api_key)
    if result:
        return result

    # 3. FDA BE Guidance
    result = _search_fda_guidance(term, folder_id, api_key)
    if result:
        return result

    # 4. Broad internet
    result = _search_broad_internet(term, folder_id, api_key)
    if result:
        return result

    return None


def _search_fda_guidance(
    term: str, folder_id: str, api_key: str,
) -> Optional[CVintraResult]:
    """
    –ò—â–µ—Ç CVintra –≤ FDA/EMA BE Guidance Documents.

    FIX #3: –ï—Å–ª–∏ CVintra = 30.0% ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (—ç—Ç–æ –ø–æ—Ä–æ–≥ HVD, –Ω–µ —Ä–µ–∞–ª—å–Ω—ã–π CV).
    """
    queries = [
        f'Notes on the Design of Bioequivalence Study {term}',
        f'bioequivalence study {term} within-subject variability Cmax coefficient of variation',
        f'{term} generic bioequivalence Cmax intra-individual variability percent',
    ]

    for query in queries:
        answer = _call_yandex_world(query, folder_id, api_key)
        if not answer or "not found" in answer.lower():
            continue

        cv = _extract_cv_from_text(answer)
        if cv is not None:
            source_name = _extract_source_name(answer) or f"FDA BE Guidance for {term}"

            # FIX #3: 30.0% –∏–∑ Guidance ‚Äî —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ø–æ—Ä–æ–≥ HVD
            if cv == 30.0:
                print(
                    f"   ‚ö†Ô∏è  BE Guidance ({term}): CVintra=30.0% ‚Äî "
                    f"–≤–µ—Ä–æ—è—Ç–Ω–æ –ø–æ—Ä–æ–≥ HVD, –∞ –Ω–µ —Ä–µ–∞–ª—å–Ω—ã–π CVintra. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º."
                )
                continue

            print(f"   ‚úÖ BE Guidance ({term}): CVintra={cv}% [{source_name}]")
            return CVintraResult(
                cv_intra=cv, source="guidance",
                source_detail=source_name,
                confidence="high", method="lookup",
            )

    print(f"   ‚ö†Ô∏è  BE Guidance: –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è '{term}'")
    return None


def _search_pubmed_ci(
    term: str, folder_id: str, api_key: str,
) -> Optional[CVintraResult]:
    """–ò—â–µ—Ç 90% CI –∏–∑ PubMed BE-—Å—Ç–∞—Ç–µ–π ‚Üí —Ä–∞—Å—á—ë—Ç CVintra."""
    queries = [
        f'{term} bioequivalence study 90% confidence interval Cmax results',
        f'{term} bioequivalence Cmax AUC 90 CI healthy volunteers crossover',
    ]

    for query in queries:
        answer = _call_yandex_world(query, folder_id, api_key)
        if not answer:
            continue

        ci = _extract_ci_from_text(answer)
        if ci is None:
            continue

        lower, upper, n, design = ci
        try:
            cv = cv_from_ci(lower, upper, n, design)
        except (ValueError, ZeroDivisionError) as e:
            print(f"   ‚ö†Ô∏è  CVintra –∏–∑ CI: –æ—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞: {e}")
            continue

        print(
            f"   ‚úÖ PubMed CI ({term}): 90% CI=[{lower:.2f}, {upper:.2f}], "
            f"n={n}, design={design} ‚Üí CVintra={cv}%"
        )
        return CVintraResult(
            cv_intra=cv, source="pubmed_ci",
            source_detail=f"Calculated from 90% CI [{lower:.2f}-{upper:.2f}], n={n}",
            confidence="high", method="calculated_from_ci",
            ci_data={"lower": lower, "upper": upper, "n": n, "design": design},
        )

    return None


def _search_pubmed_direct(
    term: str, folder_id: str, api_key: str,
) -> Optional[CVintraResult]:
    """–ò—â–µ—Ç –ø—Ä—è–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ CVintra –∏–∑ PubMed."""
    queries = [
        f'{term} bioequivalence intra-subject variability Cmax coefficient of variation',
        f'{term} pharmacokinetic variability within-subject Cmax bioequivalence study',
    ]

    for query in queries:
        answer = _call_yandex_world(query, folder_id, api_key)
        if not answer:
            continue

        cv = _extract_cv_from_text(answer)
        if cv is not None:
            source_name = _extract_source_name(answer) or f"PubMed: {term} bioequivalence"
            print(f"   ‚úÖ PubMed direct ({term}): CVintra={cv}% [{source_name}]")
            return CVintraResult(
                cv_intra=cv, source="pubmed_direct",
                source_detail=source_name,
                confidence="medium", method="lookup",
            )

    return None


def _search_broad_internet(
    term: str, folder_id: str, api_key: str,
) -> Optional[CVintraResult]:
    """–®–∏—Ä–æ–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É ‚Äî –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞."""
    queries = [
        f'{term} bioequivalence Cmax intra-subject variability coefficient of variation',
        f'{term} generic bioequivalence study sample size within-subject variability',
        f'{term} bioequivalence 90 confidence interval Cmax healthy volunteers',
        f'{term} pharmacokinetics Cmax high variability bioequivalence',
    ]

    for query in queries:
        answer = _call_yandex_world(query, folder_id, api_key)
        if not answer:
            continue

        cv = _extract_cv_from_text(answer)
        if cv is not None:
            source_name = _extract_source_name(answer) or f"Internet search: {term}"
            print(f"   ‚úÖ Broad search ({term}): CVintra={cv}% [{source_name}]")
            return CVintraResult(
                cv_intra=cv, source="internet",
                source_detail=source_name,
                confidence="low", method="lookup",
            )

        ci = _extract_ci_from_text(answer)
        if ci is not None:
            lower, upper, n, design = ci
            try:
                cv = cv_from_ci(lower, upper, n, design)
                print(
                    f"   ‚úÖ Broad search CI ({term}): "
                    f"90% CI=[{lower:.2f}, {upper:.2f}], n={n} ‚Üí CVintra={cv}%"
                )
                return CVintraResult(
                    cv_intra=cv, source="internet_ci",
                    source_detail=f"Internet: 90% CI [{lower:.2f}-{upper:.2f}], n={n}",
                    confidence="low", method="calculated_from_ci",
                    ci_data={"lower": lower, "upper": upper, "n": n, "design": design},
                )
            except (ValueError, ZeroDivisionError):
                continue

    print(f"   ‚ö†Ô∏è  Broad search: –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–ª—è '{term}'")
    return None


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ü–ê–†–°–ò–ù–ì –û–¢–í–ï–¢–û–í (–ò–°–ü–†–ê–í–õ–ï–ù–û v2 ‚Äî sentence-boundary)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _extract_cv_from_text(text: str) -> Optional[float]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç CVintra –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π.

    –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï v2: Sentence-boundary –∫–æ–Ω—Ç–µ–∫—Å—Ç.
    –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –í–ù–£–¢–†–ò –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø (–æ—Ç —Ç–æ—á–∫–∏ –¥–æ —Ç–æ—á–∫–∏),
    —á—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç ¬´—É—Ç–µ—á–∫—É¬ª –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ —Å–æ—Å–µ–¥–Ω–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.

    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –±–∞–∫–µ—Ç–æ–≤:
      1. intra-subject + Cmax  ‚Üí –õ–£–ß–®–ï–ï
      2. intra-subject         ‚Üí –•–û–†–û–®–ï–ï
      3. Cmax (–±–µ–∑ intra)      ‚Üí OK
      4. –ü—Ä–æ—á–∏–µ                ‚Üí FALLBACK

    –§–∏–ª—å—Ç—Ä—É–µ—Ç:
      - inter-subject / between-subject ‚Üí SKIP
      - AUC-–∫–æ–Ω—Ç–µ–∫—Å—Ç ‚Üí –Ω–µ –ø—É—Ç–∞—Ç—å —Å Cmax
      - 30.0% ‚Üí –ø–æ—Ä–æ–≥ HVD, –∞ –Ω–µ —Ä–µ–∞–ª—å–Ω—ã–π CVintra
    """

    BAD_CONTEXT = re.compile(
        r'between.?subject|inter.?subject|inter.?individual|'
        r'–º–µ–∂–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω|–º–µ–∂–¥—É\s*—Å—É–±—ä–µ–∫—Ç|between.?group',
        re.IGNORECASE
    )
    INTRA_CONTEXT = re.compile(
        r'within.?subject|intra.?subject|intra.?individual|'
        r'–≤–Ω—É—Ç—Ä–∏–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω|CVintra|CVw[RrTt]?[\s=]|intra-subject',
        re.IGNORECASE
    )
    CMAX_CONTEXT = re.compile(
        r'Cmax|C_?max|peak\s+concentr|–º–∞–∫—Å–∏–º–∞–ª—å–Ω\w+\s+–∫–æ–Ω—Ü–µ–Ω—Ç—Ä',
        re.IGNORECASE
    )
    AUC_CONTEXT = re.compile(
        r'\bAUC\b|area\s+under|–ø–ª–æ—â–∞–¥\w+\s+–ø–æ–¥\s+–∫—Ä–∏–≤–æ–π',
        re.IGNORECASE
    )

    intra_cmax = []
    intra_other = []
    general_cmax = []
    general_other = []

    for m in re.finditer(r'(\d+(?:\.\d+)?)\s*%', text):
        val = float(m.group(1))

        # –ë–∞–∑–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        if not (5 <= val <= 120):
            continue
        if val == 30.0:
            continue  # 30% ‚Äî —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ø–æ—Ä–æ–≥ HVD

        # ‚îÄ‚îÄ –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –¢–ï–ö–£–©–ï–ì–û –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è ‚îÄ‚îÄ
        # –ù–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: –ø—Ä–µ–¥—ã–¥—É—â–∞—è —Ç–æ—á–∫–∞
        before_text = text[:m.start()]
        sent_start = before_text.rfind('.')
        sent_start = sent_start + 1 if sent_start != -1 else 0

        # –ö–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: —Å–ª–µ–¥—É—é—â–∞—è —Ç–æ—á–∫–∞
        after_text = text[m.end():]
        sent_end_rel = after_text.find('.')
        sent_end = m.end() + sent_end_rel if sent_end_rel != -1 else len(text)

        ctx_before = text[sent_start:m.end()]    # –û—Ç –Ω–∞—á–∞–ª–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ —á–∏—Å–ª–∞
        ctx_after = text[m.end():sent_end]        # –û—Ç —á–∏—Å–ª–∞ –¥–æ –∫–æ–Ω—Ü–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è

        # –§–∏–ª—å—Ç—Ä—É–µ–º inter-subject / between-subject
        if BAD_CONTEXT.search(ctx_before):
            continue

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø
        is_intra = bool(INTRA_CONTEXT.search(ctx_before))
        is_cmax = bool(CMAX_CONTEXT.search(ctx_before + ctx_after))

        # AUC-–∫–æ–Ω—Ç–µ–∫—Å—Ç –ü–û–°–õ–ï —á–∏—Å–ª–∞ ‚Üí —ç—Ç–æ –Ω–µ Cmax
        if AUC_CONTEXT.search(ctx_after):
            is_cmax = False
        # AUC-–∫–æ–Ω—Ç–µ–∫—Å—Ç –î–û —á–∏—Å–ª–∞ –±–µ–∑ Cmax ‚Üí —Ç–æ–∂–µ –Ω–µ Cmax
        if AUC_CONTEXT.search(ctx_before) and not CMAX_CONTEXT.search(ctx_before):
            is_cmax = False

        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –ø–æ –±–∞–∫–µ—Ç–∞–º
        if is_intra and is_cmax:
            intra_cmax.append(val)
        elif is_intra:
            intra_other.append(val)
        elif is_cmax:
            general_cmax.append(val)
        else:
            general_other.append(val)

    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: intra+Cmax > intra > Cmax > other
    # –ë–µ—Ä—ë–º –ü–ï–†–í–û–ï –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –±–∞–∫–µ—Ç–∞ (–ø–æ—Ä—è–¥–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ = –ø–æ—Ä—è–¥–æ–∫
    # —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ). –ù–ï max() ‚Äî max –º–æ–∂–µ—Ç –≤–∑—è—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ 
    # —Å–æ—Å–µ–¥–Ω–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–¥—Ä—É–≥–æ–π –ø—Ä–µ–ø–∞—Ä–∞—Ç –≤ —Ç–∞–±–ª–∏—Ü–µ, inter-subject –∏ —Ç.–ø.)
    for bucket in [intra_cmax, intra_other, general_cmax, general_other]:
        if bucket:
            return round(bucket[0], 1)

    # Fallback: "CV = 0.XX" —Ñ–æ—Ä–º–∞—Ç (–±–µ–∑ %)
    decimal_match = re.search(r'CV\s*=\s*0\.(\d{2,})', text)
    if decimal_match:
        val = float(f"0.{decimal_match.group(1)}") * 100
        if 5 <= val <= 120 and val != 30.0:
            return round(val, 1)

    return None


def _extract_ci_from_text(text: str) -> Optional[Tuple[float, float, int, str]]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç 90% CI, N –∏ –¥–∏–∑–∞–π–Ω –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    ci_patterns = [
        r'90\s*%\s*CI[:\s]*\[?(\d+\.?\d*)\s*[-‚Äì,]\s*(\d+\.?\d*)\]?',
        r'confidence\s+interval[:\s]*(\d+\.?\d*)\s*(?:to|[-‚Äì])\s*(\d+\.?\d*)',
        r'lower[:\s]*(\d+\.?\d*)[^.]*upper[:\s]*(\d+\.?\d*)',
        r'\[(\d+\.?\d*)\s*%?\s*[-‚Äì,]\s*(\d+\.?\d*)\s*%?\]',
    ]

    lower, upper = None, None
    for pattern in ci_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            lower = float(match.group(1))
            upper = float(match.group(2))
            break

    if lower is None or upper is None:
        return None

    if lower > 2:
        lower = lower / 100
    if upper > 2:
        upper = upper / 100

    if not (0.5 < lower < 1.5 and 0.5 < upper < 1.5 and lower < upper):
        return None

    n = None
    n_patterns = [
        r'(?:n\s*=|subjects?|participants?|volunteers?)[:\s]*(\d+)',
        r'(\d+)\s*(?:subjects?|participants?|volunteers?|healthy)',
    ]
    for pattern in n_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            val = int(match.group(1))
            if 6 <= val <= 200:
                n = val
                break

    if n is None:
        return None

    design = "2x2x2"
    text_lower = text.lower()
    if any(k in text_lower for k in ["4-period", "4 period", "full replicate", "2x2x4"]):
        design = "2x2x4"
    elif any(k in text_lower for k in ["3-period", "3 period", "partial replicate", "2x2x3"]):
        design = "2x2x3"
    elif any(k in text_lower for k in ["parallel"]):
        design = "parallel"

    return (lower, upper, n, design)


def _extract_source_name(text: str) -> Optional[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞/—Å—Ç–∞—Ç—å–∏."""
    patterns = [
        r'Notes on the Design[^.\n]+',
        r'Product[- ]Specific Guidance[^.\n]+',
        r'Guidance Document[^.\n]+',
        r'PMID[:\s]*\d+',
    ]
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            return match.group(0).strip()
    return None


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –£–¢–ò–õ–ò–¢–´
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _call_yandex_world(query: str, folder_id: str, api_key: str) -> str:
    """–í—ã–∑–æ–≤ Yandex GenSearch."""
    body = {
        "messages": [{"content": query, "role": "ROLE_USER"}],
        "folder_id": folder_id,
    }
    headers = {
        "Authorization": f"Api-Key {api_key}",
        "Content-Type": "application/json",
    }
    try:
        resp = requests.post(YANDEX_GEN_SEARCH_URL, json=body, headers=headers, timeout=25)
        if resp.status_code != 200:
            print(f"   ‚ö†Ô∏è  Yandex HTTP {resp.status_code}: {resp.text[:200]}")
            return ""
        data = resp.json()

        if isinstance(data, list):
            data = data[0] if data else {}

        message = data.get("message", {})
        if isinstance(message, list):
            message = message[0] if message else {}
        if isinstance(message, dict):
            content = message.get("content", "")
            if isinstance(content, list):
                parts = []
                for item in content:
                    if isinstance(item, dict):
                        parts.append(str(item.get("content", item.get("text", ""))))
                    elif isinstance(item, str):
                        parts.append(item)
                content = " ".join(parts)
        else:
            content = ""

        sources = data.get("sources", [])
        if sources:
            source_urls = []
            for s in sources:
                if isinstance(s, dict):
                    url = s.get("url", "")
                    title = s.get("title", "")
                    if url:
                        source_urls.append(f"[SOURCE: {title} | {url}]")
            if source_urls:
                content += "\n" + "\n".join(source_urls)

        return content if isinstance(content, str) else ""
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Yandex Search: {e}")
        return ""


def _unique(items: list) -> list:
    """–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–µ–ø—É—Å—Ç—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã."""
    seen = set()
    result = []
    for item in items:
        if item and item not in seen:
            seen.add(item)
            result.append(item)
    return result


def _default_result() -> CVintraResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."""
    return CVintraResult(
        cv_intra=30.0,
        source="default",
        source_detail="–ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (–Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ)",
        confidence="low",
        method="default",
    )


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ü–û–ò–°–ö –§–ö-–ü–ê–†–ê–ú–ï–¢–†–û–í (T¬Ω, Tmax, Cmax) –ü–û PUBMED
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@dataclass
class PKParamsResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ –§–ö-–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
    t_half_hours: Optional[float] = None
    tmax_hours: Optional[float] = None
    cmax_value: Optional[float] = None
    cmax_unit: str = ""
    source: str = ""
    source_detail: str = ""


def search_pk_params(
    inn_en: str,
    inn_ru: str = "",
    folder_id: Optional[str] = None,
    api_key: Optional[str] = None,
) -> PKParamsResult:
    """
    –ü–æ–∏—Å–∫ T¬Ω, Tmax, Cmax –ø–æ PubMed/FDA/–∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—Ç –∂–µ Yandex Search API —á—Ç–æ –∏ CVintra.
    """
    folder_id = folder_id or os.getenv("YANDEX_FOLDER_ID", "")
    api_key = api_key or os.getenv("YANDEX_API_KEY", "")

    if not folder_id or not api_key:
        return PKParamsResult()

    inn_ru_base, inn_en_base = normalize_inn(inn_ru, inn_en if inn_en else None)
    if not inn_en_base and inn_ru:
        inn_en_base = resolve_inn_en(inn_ru)
    term = inn_en_base or inn_en or inn_ru_base or inn_ru

    queries = [
        f'{term} pharmacokinetics half-life Cmax Tmax single dose healthy volunteers',
        f'{term} half-life elimination terminal single oral dose pharmacokinetic parameters',
        f'{term} pharmacokinetic profile AUC Cmax Tmax elimination half-life hours',
    ]

    # –†—É—Å—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã ‚Äî –∏—â—É—Ç –ø–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏/–ì–†–õ–°
    inn_ru_term = inn_ru_base or inn_ru
    if inn_ru_term:
        queries.extend([
            f'{inn_ru_term} –ø–µ—Ä–∏–æ–¥ –ø–æ–ª—É–≤—ã–≤–µ–¥–µ–Ω–∏—è —Ñ–∞—Ä–º–∞–∫–æ–∫–∏–Ω–µ—Ç–∏–∫–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è',
            f'{inn_ru_term} T1/2 —Ñ–∞—Ä–º–∞–∫–æ–∫–∏–Ω–µ—Ç–∏–∫–∞ –æ–¥–Ω–æ–∫—Ä–∞—Ç–Ω—ã–π –ø—Ä–∏—ë–º',
        ])

    result = PKParamsResult()

    for query in queries:
        answer = _call_yandex_world(query, folder_id, api_key)
        if not answer:
            continue

        # –ò–∑–≤–ª–µ–∫–∞–µ–º T¬Ω
        if result.t_half_hours is None:
            t_half = _extract_t_half_from_text(answer)
            if t_half is not None:
                result.t_half_hours = t_half
                result.source = "pubmed_pk"
                result.source_detail = _extract_source_name(answer) or f"PubMed PK: {term}"
                print(f"   ‚úÖ PubMed PK ({term}): T¬Ω={t_half} —á [{result.source_detail}]")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º Tmax
        if result.tmax_hours is None:
            tmax = _extract_tmax_from_text(answer)
            if tmax is not None:
                result.tmax_hours = tmax

        # –ò–∑–≤–ª–µ–∫–∞–µ–º Cmax
        if result.cmax_value is None:
            cmax, unit = _extract_cmax_from_text(answer)
            if cmax is not None:
                result.cmax_value = cmax
                result.cmax_unit = unit

        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ T¬Ω ‚Äî –æ—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–ª—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞
        if result.t_half_hours is not None:
            break

    return result


def _extract_t_half_from_text(text: str) -> Optional[float]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç T¬Ω –∏–∑ —Ç–µ–∫—Å—Ç–∞ PubMed/FDA –æ—Ç–≤–µ—Ç–∞.

    –í–ê–ñ–ù–û: –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –ß–ê–°–ê–•.
    –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ "12 days" ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 288.0
    –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ "12 hours" ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 12.0
    """
    t = text.lower()

    patterns = [
        # "t1/2 = 12 h" / "t¬Ω = 12 days" ‚Äî —Å–∞–º—ã–π –Ω–∞–¥—ë–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        r'(?:t\s*1\s*/\s*2|t¬Ω|t1/2)\s*(?:[=:\-‚Äì‚Äî]\s*|(?:of|is|was)\s+)'
        r'(\d+[.,]?\d*)\s*(hours?|hrs?|h\b|days?|d\b|minutes?|min|weeks?|wk)',

        # "terminal half-life of 12 days" / "elimination half-life was approximately 12 h"
        r'(?:terminal\s+)?(?:elimination\s+)?half[- ]?life'
        r'(?:\s+(?:of\s+)?(?:the\s+)?(?:drug\s+)?(?:is\s+|was\s+|of\s+)?(?:approximately\s+|about\s+|~\s*)?)?'
        r'(\d+[.,]?\d*)\s*(hours?|hrs?|h\b|days?|d\b|minutes?|min|weeks?|wk)',

        # "half-life of approximately 12 days" ‚Äî —Å –ø—Ä–æ–º–µ–∂—É—Ç–∫–æ–º –¥–æ 80 —Å–∏–º–≤–æ–ª–æ–≤
        r'half[- ]?life'
        r'(?:[^.]{0,80}?)'
        r'(?:of|is|was|approximately|about|~|=|:)\s*'
        r'(\d+[.,]?\d*)\s*(hours?|hrs?|h\b|days?|d\b|minutes?|min|weeks?|wk)',

        # "half-life 12 days" ‚Äî –ø—Ä—è–º–æ —Ä—è–¥–æ–º
        r'half[- ]?life\s+(\d+[.,]?\d*)\s*(hours?|hrs?|h\b|days?|d\b|min|weeks?|wk)',

        # –†—É—Å—Å–∫–∏–π: "–ø–µ—Ä–∏–æ–¥ –ø–æ–ª—É–≤—ã–≤–µ–¥–µ–Ω–∏—è —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 12 —Å—É—Ç–æ–∫"
        r'–ø–µ—Ä–∏–æ–¥\s+–ø–æ–ª—É[- ]?(?:–≤—ã–≤–µ–¥–µ–Ω–∏—è|—ç–ª–∏–º–∏–Ω–∞—Ü–∏–∏)'
        r'(?:[^.]{0,120}?)'
        r'(?:—Å–æ—Å—Ç–∞–≤–ª—è\w+|—Ä–∞–≤–µ–Ω|—Ä–∞–≤–Ω–∞|–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ|–ø—Ä–∏–º–µ—Ä–Ω–æ|–æ–∫–æ–ª–æ|~|‚âà|=|:)\s*'
        r'(\d+[.,]?\d*)\s*(—á–∞—Å(?:–æ–≤|–∞|—ã)?|—á\b|–º–∏–Ω\w*|—Å—É—Ç(?:–æ–∫|–∫–∏)?|–¥–Ω(?:–µ–π|—è)?|–¥–µ–Ω—å|–Ω–µ–¥\w*)',

        # –†—É—Å—Å–∫–∏–π: "T¬Ω —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 12 —Å—É—Ç–æ–∫"
        r'(?:t\s*1\s*/\s*2|t¬Ω)\s*(?:—Å–æ—Å—Ç–∞–≤–ª—è\w+|—Ä–∞–≤–µ–Ω|—Ä–∞–≤–Ω–∞|=|:|-)\s*'
        r'(\d+[.,]?\d*)\s*(—á–∞—Å(?:–æ–≤|–∞|—ã)?|—á\b|–º–∏–Ω\w*|—Å—É—Ç(?:–æ–∫|–∫–∏)?|–¥–Ω(?:–µ–π|—è)?|–¥–µ–Ω—å|–Ω–µ–¥\w*)',
    ]

    for pat in patterns:
        m = re.search(pat, t)
        if m:
            val_str = m.group(1).replace(',', '.')
            try:
                val = float(val_str)
            except ValueError:
                continue

            unit = m.group(2).lower().strip()
            hours = _pk_unit_to_hours(val, unit)

            if hours is None:
                continue

            # –°–∞–Ω–∏—Ç–∞—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            if hours < 0.01 or hours > 10000:
                continue

            # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            if hours != val:
                print(f"   üìê T¬Ω –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: {val} {unit} ‚Üí {hours} —á")

            return hours

    return None


def _extract_tmax_from_text(text: str) -> Optional[float]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç Tmax –∏–∑ —Ç–µ–∫—Å—Ç–∞ PubMed."""
    t = text.lower()
    patterns = [
        r'(?:tmax|t\s*max)\s*(?:[=:\-‚Äì‚Äî]\s*|(?:of|is|was)\s+)'
        r'(\d+[.,]?\d*)\s*(hours?|h|days?|d|min)',
        r'(?:time\s+to\s+(?:peak|maximum)\s+(?:concentration|cmax))'
        r'(?:[^.]{0,60}?)'
        r'(?:of|is|was|approximately)\s*'
        r'(\d+[.,]?\d*)\s*(hours?|h|days?|d|min)',
    ]
    for pat in patterns:
        m = re.search(pat, t)
        if m:
            val_str = m.group(1).replace(',', '.')
            try:
                val = float(val_str)
            except ValueError:
                continue
            hours = _pk_unit_to_hours(val, m.group(2).lower())
            if hours and 0.01 < hours < 500:
                return hours
    return None


def _extract_cmax_from_text(text: str) -> tuple:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç Cmax –∏–∑ —Ç–µ–∫—Å—Ç–∞ PubMed. Returns (value, unit) or (None, '')."""
    t = text.lower()
    patterns = [
        r'(?:cmax|c\s*max|peak\s+(?:plasma\s+)?concentration)'
        r'(?:[^.]{0,60}?)'
        r'(?:of|is|was|=)\s*'
        r'(\d+[.,]?\d*)\s*(ng/ml|¬µg/ml|mg/ml|Œºg/ml|–Ω–≥/–º–ª|–º–∫–≥/–º–ª)',
    ]
    for pat in patterns:
        m = re.search(pat, t)
        if m:
            val_str = m.group(1).replace(',', '.')
            try:
                return float(val_str), m.group(2)
            except ValueError:
                continue
    return None, ""


def _pk_unit_to_hours(val: float, unit: str) -> Optional[float]:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç PK-–µ–¥–∏–Ω–∏—Ü—ã –≤ —á–∞—Å—ã.

    –í–ê–ñ–ù–û: –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None (–Ω–µ val!).
    –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –±–∞–≥ "12 days ‚Üí 12 hours".
    """
    u = unit.lower().strip()

    # –ß–∞—Å—ã
    if u in ('h', 'hr', 'hrs', 'hour', 'hours') or u.startswith('—á–∞—Å'):
        return val

    # –ú–∏–Ω—É—Ç—ã
    if u in ('min', 'minute', 'minutes') or u.startswith('–º–∏–Ω'):
        return val / 60

    # –î–Ω–∏ / —Å—É—Ç–∫–∏
    if u in ('d', 'day', 'days') or u.startswith('—Å—É—Ç') or u.startswith('–¥–Ω') or u == '–¥–µ–Ω—å':
        return val * 24

    # –ù–µ–¥–µ–ª–∏
    if u in ('wk', 'week', 'weeks') or u.startswith('–Ω–µ–¥'):
        return val * 24 * 7

    # –†—É—Å—Å–∫–æ–µ "—á" ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–æ–≤–Ω–æ "—á" (–Ω–µ –Ω–∞—á–∞–ª–æ –¥—Ä—É–≥–æ–≥–æ —Å–ª–æ–≤–∞)
    if u == '—á':
        return val

    # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –µ–¥–∏–Ω–∏—Ü–∞ ‚Äî –ù–ï –≤–æ–∑–≤—Ä–∞—â–∞–µ–º val, —Ç.–∫. –º–æ–∂–µ–º –ø–µ—Ä–µ–ø—É—Ç–∞—Ç—å –¥–Ω–∏ —Å —á–∞—Å–∞–º–∏
    print(f"   ‚ö†Ô∏è T¬Ω: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –µ–¥–∏–Ω–∏—Ü–∞ '{unit}' –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏—è {val}")
    return None