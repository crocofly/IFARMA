"""
rag/rag_index.py ‚Äî –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –†–µ—à–µ–Ω–∏—è ‚Ññ85 –≤ ChromaDB.

–†–∞–∑–±–∏–≤–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —á–∞–Ω–∫–∏ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º/–ø–æ–¥—Ä–∞–∑–¥–µ–ª–∞–º,
—Å–æ–∑–¥–∞—ë—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è semantic search.

–ó–∞–ø—É—Å–∫:
    python -m app.rag.rag_index --input data/–†–µ—à–µ–Ω–∏–µ85.docx --db data/chroma_db

–ò–ª–∏ –∏–∑ –∫–æ–¥–∞:
    from app.rag.rag_index import index_decision85
    index_decision85("data/–†–µ—à–µ–Ω–∏–µ85.docx", "data/chroma_db")
"""

import argparse
import os
import re
from typing import List, Dict

from docx import Document


# ‚îÄ‚îÄ –ú–∞—Ä–∫–µ—Ä—ã —Ä–∞–∑–¥–µ–ª–æ–≤ –†–µ—à–µ–Ω–∏—è 85 ‚îÄ‚îÄ

SECTION_MARKERS = [
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
    "I. –û–±—â–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è",
    "II. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è",
    "III. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–∏–∑–∞–π–Ω—É, –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—é –∏ –æ—Ü–µ–Ω–∫–µ",
    "1. –î–∏–∑–∞–π–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
    "2. –†–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω—ã–π –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–µ–ø–∞—Ä–∞—Ç",
    "–ò—Å—Å–ª–µ–¥—É–µ–º—ã–π –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–µ–ø–∞—Ä–∞—Ç",
    "–£–ø–∞–∫–æ–≤–∫–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º—ã—Ö",
    "3. –°—É–±—ä–µ–∫—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
    "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É–±—ä–µ–∫—Ç–æ–≤",
    "–í—ã–±–æ—Ä —Å—É–±—ä–µ–∫—Ç–æ–≤",
    "4. –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
    "–û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ—Å—Ç–∏",
    "–í—Ä–µ–º—è –æ—Ç–±–æ—Ä–∞ –æ–±—Ä–∞–∑—Ü–æ–≤",
    "–ü—Ä–∏–µ–º –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞ –Ω–∞—Ç–æ—â–∞–∫",
    "5. –ò—Å—Å–ª–µ–¥—É–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã",
    "–§–∞—Ä–º–∞–∫–æ–∫–∏–Ω–µ—Ç–∏—á–µ—Å–∫–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞",
    "6. –ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–ª–∏ –µ–≥–æ –º–µ—Ç–∞–±–æ–ª–∏—Ç—ã",
    "–û–±—â–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã",
    "–ù–µ–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–ª–µ–∫–∞—Ä—Å—Ç–≤–∞",
    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –º–µ—Ç–∞–±–æ–ª–∏—Ç–µ",
    "–≠–Ω–∞–Ω—Ç–∏–æ–º–µ—Ä—ã",
    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ—á–∏",
    "–≠–Ω–¥–æ–≥–µ–Ω–Ω—ã–µ –≤–µ—â–µ—Å—Ç–≤–∞",
    "7. –ò—Å—Å–ª–µ–¥—É–µ–º—ã–µ –¥–æ–∑–∏—Ä–æ–≤–∫–∏",
    "–û–±—â–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –±–∏–æ–≤–µ–π–≤–µ—Ä–∞",
    "–õ–∏–Ω–µ–π–Ω–∞—è —Ñ–∞—Ä–º–∞–∫–æ–∫–∏–Ω–µ—Ç–∏–∫–∞",
    "–ù–µ–ª–∏–Ω–µ–π–Ω–∞—è —Ñ–∞—Ä–º–∞–∫–æ–∫–∏–Ω–µ—Ç–∏–∫–∞",
    "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∫—Ä–∞–π–Ω–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤",
    "–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç—ã",
    "8. –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –±–∏–æ–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π —á–∞—Å—Ç–∏",
    "9. –û—Ü–µ–Ω–∫–∞, –∞–Ω–∞–ª–∏–∑ –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
    "–û—Ç–±–æ—Ä —Å—É–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
    "–ö—Ä–∏—Ç–µ—Ä–∏–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è —Å—É–±—ä–µ–∫—Ç–æ–≤ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞",
    "–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –ø—Ä–µ–¥–µ–ª—ã",
    "–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑",
    "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥—Ä—É–ø–ø–∞—Ö",
    "–≠—Ñ—Ñ–µ–∫—Ç—ã –ø–µ—Ä–µ–Ω–æ—Å–∞",
    "–î–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –¥–∏–∑–∞–π–Ω",
    "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö",
    "10. –õ–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç—ã —Å —É–∑–∫–∏–º —Ç–µ—Ä–∞–ø–µ–≤—Ç–∏—á–µ—Å–∫–∏–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º",
    "11. –õ–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç—ã —Å –≤—ã—Å–æ–∫–æ–π –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å—é",
    # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    "IV. –¢–µ—Å—Ç —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∫–∏–Ω–µ—Ç–∏–∫–∏ —Ä–∞—Å—Ç–≤–æ—Ä–µ–Ω–∏—è",
    "V. –û—Ç—á–µ—Ç –æ–± –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏",
    "VI. –û–±—ä–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –ø—Ä–∏ –≤–Ω–µ—Å–µ–Ω–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π",
    # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ 1 ‚Äî –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã
    "–õ–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã –¥–ª—è –ø—Ä–∏–µ–º–∞ –≤–Ω—É—Ç—Ä—å —Å –Ω–µ–º–µ–¥–ª–µ–Ω–Ω—ã–º –≤—ã—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ–º",
    "–¢–∞–±–ª–µ—Ç–∫–∏, –¥–∏—Å–ø–µ—Ä–≥–∏—Ä—É—é—â–∏–µ—Å—è –≤ –ø–æ–ª–æ—Å—Ç–∏ —Ä—Ç–∞",
    "–†–∞—Å—Ç–≤–æ—Ä—ã –¥–ª—è –ø—Ä–∏–µ–º–∞ –≤–Ω—É—Ç—Ä—å",
    "–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç—ã",
    "–†–∞—Å—Ç–≤–æ—Ä—ã –¥–ª—è –ø–∞—Ä–µ–Ω—Ç–µ—Ä–∞–ª—å–Ω–æ–≥–æ –≤–≤–µ–¥–µ–Ω–∏—è",
    "–õ–∏–ø–æ—Å–æ–º–∞–ª—å–Ω—ã–µ, –º–∏—Ü–µ–ª–ª—è—Ä–Ω—ã–µ",
    "–õ–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã —Å –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤—ã—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ–º",
    # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è –ø–æ –ë–ö–°
    "–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ë–ò–û–í–ï–ô–í–ï–†–£",
    # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ 6 ‚Äî –≤–∞–ª–∏–¥–∞—Ü–∏—è
    "–í–∞–ª–∏–¥–∞—Ü–∏—è –±–∏–æ–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π –º–µ—Ç–æ–¥–∏–∫–∏",
    # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ 7 ‚Äî –æ—Ç—á—ë—Ç
    "–û—Ç—á–µ—Ç –æ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –±–∏–æ—ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç–∏",
    # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ 8 ‚Äî –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è –§–ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    "–£–°–õ–û–í–ù–´–ï –û–ë–û–ó–ù–ê–ß–ï–ù–ò–Ø –§–ê–†–ú–ê–ö–û–ö–ò–ù–ï–¢–ò–ß–ï–°–ö–ò–• –ü–ê–†–ê–ú–ï–¢–†–û–í",
    # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ 10 ‚Äî –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—ã—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ
    "–º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤—ã—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ–º",
    # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ 13 ‚Äî –º–µ—Å—Ç–Ω–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ
    "–º–µ—Å—Ç–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è",
]


def _is_section_start(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ –Ω–∞—á–∞–ª–æ–º –Ω–æ–≤–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞."""
    text_clean = text.strip()
    if not text_clean:
        return False

    # –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç (< 120 —Å–∏–º–≤–æ–ª–æ–≤) ‚Äî –≤–æ–∑–º–æ–∂–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    if len(text_clean) > 150:
        return False

    for marker in SECTION_MARKERS:
        if marker.lower() in text_clean.lower():
            return True

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤: "1.", "II.", "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"
    if re.match(r'^(I{1,3}V?|V?I{0,3})\.\s', text_clean):
        return True
    if re.match(r'^\d{1,2}\.\s+[–ê-–Ø]', text_clean):
        return True
    if text_clean.startswith("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"):
        return True
    if text_clean.startswith("–¢–†–ï–ë–û–í–ê–ù–ò–Ø"):
        return True
    if text_clean.startswith("–ü–†–ê–í–ò–õ–ê"):
        return True

    return False


def _extract_section_title(text: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ä–∞–∑–¥–µ–ª–∞."""
    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 120 —Å–∏–º–≤–æ–ª–æ–≤ –¥–æ —Ç–æ—á–∫–∏ –∏–ª–∏ –ø–µ—Ä–µ–Ω–æ—Å–∞
    first_line = text.split("\n")[0].strip()
    if len(first_line) > 120:
        first_line = first_line[:120] + "..."
    return first_line


def split_into_chunks(docx_path: str, max_chunk_chars: int = 2000) -> List[Dict]:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç –†–µ—à–µ–Ω–∏–µ 85 –Ω–∞ —á–∞–Ω–∫–∏ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º.

    –°—Ç—Ä–∞—Ç–µ–≥–∏—è:
    - –ö–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª (–ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É) ‚Üí –æ—Ç–¥–µ–ª—å–Ω—ã–π —á–∞–Ω–∫
    - –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª > max_chunk_chars ‚Üí —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
    - –ö–∞–∂–¥—ã–π —á–∞–Ω–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç: id, section, text, char_count

    Args:
        docx_path: –ü—É—Ç—å –∫ .docx —Ñ–∞–π–ª—É –†–µ—à–µ–Ω–∏—è 85
        max_chunk_chars: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö

    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —á–∞–Ω–∫–∞–º–∏
    """
    doc = Document(docx_path)
    paragraphs = [p.text.strip() for p in doc.paragraphs]

    chunks = []
    current_section = "–ü—Ä–µ–∞–º–±—É–ª–∞"
    current_text = []
    current_chars = 0

    def _flush():
        nonlocal current_text, current_chars
        if current_text:
            text = "\n".join(current_text)
            if text.strip():
                chunks.append({
                    "section": current_section,
                    "text": text.strip(),
                    "char_count": len(text),
                })
            current_text = []
            current_chars = 0

    for para in paragraphs:
        if not para:
            continue

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–µ—Ç–∫–∏ —Ä–µ–¥–∞–∫—Ü–∏–π "–ù–æ–≤. —Ä–µ–¥.", "–°–º. –ø—Ä–µ–¥. —Ä–µ–¥."
        if para.startswith("–ù–æ–≤. —Ä–µ–¥.") or para.startswith("–°–º. –ø—Ä–µ–¥. —Ä–µ–¥."):
            continue

        # –ù–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª?
        if _is_section_start(para):
            _flush()
            current_section = _extract_section_title(para)

        current_text.append(para)
        current_chars += len(para)

        # –†–∞–∑–±–∏–≤–∞–µ–º —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ —á–∞–Ω–∫–∏
        if current_chars >= max_chunk_chars:
            _flush()

    _flush()

    # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º id
    for i, chunk in enumerate(chunks):
        chunk["id"] = f"r85_{i:04d}"

    return chunks


def index_decision85(
    docx_path: str,
    db_path: str = "data/chroma_db",
    collection_name: str = "decision_85",
) -> int:
    """
    –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –†–µ—à–µ–Ω–∏–µ 85 –≤ ChromaDB.

    Args:
        docx_path: –ü—É—Ç—å –∫ –†–µ—à–µ–Ω–∏–µ85.docx
        db_path: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è ChromaDB
        collection_name: –ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏

    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
    """
    import chromadb

    print(f"üìÑ –ß–∏—Ç–∞—é –¥–æ–∫—É–º–µ–Ω—Ç: {docx_path}")
    chunks = split_into_chunks(docx_path, max_chunk_chars=2000)
    print(f"‚úÇÔ∏è  –†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_chars = sum(c["char_count"] for c in chunks)
    avg_chars = total_chars // len(chunks) if chunks else 0
    print(f"üìä –í—Å–µ–≥–æ —Å–∏–º–≤–æ–ª–æ–≤: {total_chars:,}, —Å—Ä–µ–¥–Ω–µ–µ: {avg_chars}")

    # –°–æ–∑–¥–∞—ë–º / –æ—Ç–∫—Ä—ã–≤–∞–µ–º ChromaDB —Å –∫–∞—Å—Ç–æ–º–Ω–æ–π embedding function
    os.makedirs(db_path, exist_ok=True)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é —Ö–µ—à-based embedding function (—Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ñ—Ñ–ª–∞–π–Ω)
    from app.rag._embeddings import SimpleRuEmbedding
    embed_fn = SimpleRuEmbedding()

    client = chromadb.PersistentClient(path=db_path)

    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
    try:
        client.delete_collection(collection_name)
    except Exception:
        pass

    collection = client.create_collection(
        name=collection_name,
        metadata={"description": "–†–µ—à–µ–Ω–∏–µ –ï–ê–≠–° ‚Ññ85 –æ—Ç 03.11.2016 ‚Äî –ü—Ä–∞–≤–∏–ª–∞ –ë–≠"},
        embedding_function=embed_fn,
    )

    # –î–æ–±–∞–≤–ª—è–µ–º —á–∞–Ω–∫–∏
    ids = [c["id"] for c in chunks]
    documents = [c["text"] for c in chunks]
    metadatas = [{"section": c["section"], "char_count": c["char_count"]} for c in chunks]

    # ChromaDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç default embedding function
    # (onnxruntime + all-MiniLM-L6-v2)
    collection.add(
        ids=ids,
        documents=documents,
        metadatas=metadatas,
    )

    print(f"‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: {len(chunks)} —á–∞–Ω–∫–æ–≤ –≤ {db_path}")
    print(f"   –ö–æ–ª–ª–µ–∫—Ü–∏—è: {collection_name}")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–¥–µ–ª—ã
    sections = list(dict.fromkeys(c["section"] for c in chunks))
    print(f"\nüìã –†–∞–∑–¥–µ–ª—ã ({len(sections)}):")
    for s in sections[:30]:
        print(f"   ‚Ä¢ {s}")
    if len(sections) > 30:
        print(f"   ... –∏ –µ—â—ë {len(sections) - 30}")

    return len(chunks)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –†–µ—à–µ–Ω–∏—è 85 –≤ ChromaDB")
    parser.add_argument("--input", default="data/–†–µ—à–µ–Ω–∏–µ85.docx",
                        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –†–µ—à–µ–Ω–∏–µ85.docx")
    parser.add_argument("--db", default="data/chroma_db",
                        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è ChromaDB")
    parser.add_argument("--collection", default="decision_85",
                        help="–ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏")
    args = parser.parse_args()

    index_decision85(args.input, args.db, args.collection)