"""
server.py ‚Äî FastAPI-—Å–µ—Ä–≤–µ—Ä –¥–ª—è Flutter Web.
–ó–∞–ø—É—Å–∫: uvicorn server:app --reload --port 8000
Docs:   http://localhost:8000/docs
"""
import asyncio, os, uuid, traceback, json
from datetime import datetime
from typing import Any, Dict, List, Optional

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env —Ñ–∞–π–ª
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # python-dotenv –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ env

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel, Field

from app.models.common import PipelineInput
from app.pipeline.pipeline import Pipeline

# ‚ïê‚ïê‚ïê API Models ‚ïê‚ïê‚ïê
class GenerateRequest(BaseModel):
    inn_ru: str
    dosage_form: str
    dosage: str
    storage_conditions: str = ""
    drug_name_trade: Optional[str] = None
    manufacturer: Optional[str] = None
    manufacturer_is_sponsor: bool = True
    sponsor: Optional[str] = None
    protocol_id: Optional[str] = None
    protocol_mode: str = "manual"
    research_center: Optional[str] = None
    bioanalytical_lab: Optional[str] = None
    insurance_company: Optional[str] = None
    reference_drug_name: Optional[str] = None
    excipients: Optional[List[str]] = None
    cv_intra: Optional[float] = None
    t_half_hours: Optional[float] = None
    sex_restriction: str = ""
    age_min: int = 18
    age_max: int = 45
    smoking_restriction: str = ""
    # Overrides ‚Äî —Ä–∞—Å—á—ë—Ç–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
    override_power: Optional[float] = None
    override_alpha: Optional[float] = None
    override_gmr: Optional[float] = None
    override_dropout_rate: Optional[float] = None
    override_screenfail_rate: Optional[float] = None
    override_min_subjects: Optional[int] = None
    override_blood_per_point_ml: Optional[float] = None
    override_max_blood_ml: Optional[float] = None

    def to_pipeline_input(self) -> PipelineInput:
        sponsor = self.manufacturer if self.manufacturer_is_sponsor else self.sponsor
        kwargs: dict = dict(
            inn_ru=self.inn_ru, dosage_form=self.dosage_form, dosage=self.dosage,
            drug_name_trade=self.drug_name_trade, reference_drug_name=self.reference_drug_name,
            cv_intra=self.cv_intra, t_half_hours=self.t_half_hours,
            sex_restriction=self.sex_restriction if self.sex_restriction else "males_only",
            age_min=self.age_min, age_max=self.age_max,
            sponsor_name=sponsor, research_center=self.research_center,
            bioanalytical_lab=self.bioanalytical_lab, insurance_company=self.insurance_company,
            study_id=self.protocol_id,
            study_id_mode=self.protocol_mode,
            storage_conditions=self.storage_conditions or None,
            manufacturer_name=self.manufacturer,
            excipients=", ".join(self.excipients) if self.excipients else None,
        )
        # –ü–µ—Ä–µ–¥–∞—ë–º overrides —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–¥–∞–Ω—ã
        for attr in ("override_power", "override_alpha", "override_gmr",
                      "override_dropout_rate", "override_screenfail_rate",
                      "override_min_subjects", "override_blood_per_point_ml",
                      "override_max_blood_ml"):
            val = getattr(self, attr)
            if val is not None:
                kwargs[attr] = val
        return PipelineInput(**kwargs)

class StepStatus(BaseModel):
    id: str; label: str; status: str; detail: Optional[str] = None

class TaskResponse(BaseModel):
    task_id: str; status: str; progress: float = 0.0
    steps: List[StepStatus] = []; result: Optional[Dict[str, Any]] = None; error: Optional[str] = None

class HistoryItem(BaseModel):
    task_id: str; inn: str; form: str; dose: str; date: str; status: str

# ‚ïê‚ïê‚ïê Storage ‚ïê‚ïê‚ïê
tasks: Dict[str, TaskResponse] = {}
history: List[HistoryItem] = []
file_paths: Dict[str, Dict[str, str]] = {}

# ‚ïê‚ïê‚ïê App ‚ïê‚ïê‚ïê
app = FastAPI(title="iFarma API", version="1.0.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

# ‚ïê‚ïê‚ïê Generate ‚ïê‚ïê‚ïê
@app.post("/api/generate", response_model=TaskResponse)
async def generate(req: GenerateRequest, bg: BackgroundTasks):
    task_id = uuid.uuid4().hex[:8]
    task = TaskResponse(task_id=task_id, status="running", steps=[
        StepStatus(id="s1", label="PK –õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞", status="pending"),
        StepStatus(id="s2", label="–†–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–π –∞–≥–µ–Ω—Ç", status="pending"),
        StepStatus(id="s3", label="–î–∏–∑–∞–π–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è", status="pending"),
        StepStatus(id="s4", label="–†–∞—Å—á—ë—Ç –≤—ã–±–æ—Ä–∫–∏", status="pending"),
        StepStatus(id="s5", label="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω–æ–ø—Å–∏—Å–∞", status="pending"),
    ])
    tasks[task_id] = task
    history.insert(0, HistoryItem(task_id=task_id, inn=req.inn_ru, form=req.dosage_form, dose=req.dosage, date=datetime.now().strftime("%d.%m.%Y %H:%M"), status="running"))
    bg.add_task(_run, task_id, req)
    print(f"\n{'='*50}\n  üöÄ {task_id}: {req.inn_ru} {req.dosage}\n{'='*50}\n")
    return task

async def _run(task_id: str, req: GenerateRequest):
    task = tasks[task_id]
    try:
        payload = req.to_pipeline_input()
        pipeline = Pipeline()
        task.steps[0].status = "running"; task.steps[1].status = "running"; task.progress = 0.05
        result = await pipeline.run(payload)
        for s in task.steps: s.status = "done"
        task.progress = 1.0; task.result = _ser(result); task.status = "done"
        _export(task_id, payload, result)
        for h in history:
            if h.task_id == task_id: h.status = "done"; break
        print(f"  ‚úÖ {task_id} done: {req.inn_ru}")
    except Exception as e:
        traceback.print_exc(); task.status = "error"; task.error = str(e)
        for s in task.steps:
            if s.status in ("running","pending"): s.status = "error"
        for h in history:
            if h.task_id == task_id: h.status = "error"; break

def _export(task_id, payload, result):
    try:
        safe = payload.inn_ru.replace(" ","_").replace("+","_")
        d = os.path.join("output", safe); os.makedirs(d, exist_ok=True); paths = {}
        tpl = "data/—à–∞–±–ª–æ–Ω_–¥–ª—è_–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è.docx"
        if os.path.exists(tpl):
            p = os.path.join(d, f"synopsis_{task_id}.docx")
            try:
                from app.services.export.docx_exporter import export_synopsis
                export_synopsis(result, template_path=tpl, output_path=p); paths["synopsis"] = p
            except Exception as e: print(f"  ‚ö†Ô∏è synopsis export: {e}")
        try:
            p = os.path.join(d, f"rationale_{task_id}.docx")
            from app.services.export.rationale_exporter import export_rationale
            export_rationale(result, output_path=p); paths["rationale"] = p
        except Exception as e: print(f"  ‚ö†Ô∏è rationale export: {e}")
        if paths: file_paths[task_id] = paths
    except Exception as e: print(f"  ‚ö†Ô∏è export: {e}")

def _ser(result):
    out = {}
    for k, v in result.items():
        if hasattr(v, "model_dump"): out[k] = v.model_dump()
        elif isinstance(v, list): out[k] = [x.model_dump() if hasattr(x, "model_dump") else x for x in v]
        elif isinstance(v, dict): out[k] = v
        else: out[k] = str(v) if v is not None else None
    return out

@app.get("/api/generate/{task_id}", response_model=TaskResponse)
async def get_status(task_id: str):
    if task_id not in tasks: raise HTTPException(404, "Not found")
    return tasks[task_id]

@app.get("/api/download/{task_id}/{doc_type}")
async def download(task_id: str, doc_type: str):
    paths = file_paths.get(task_id, {})
    # –ï—Å–ª–∏ –µ—Å—Ç—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è ‚Äî —Å–∫–∞—á–∏–≤–∞–µ–º –µ—ë
    edited_key = f"{doc_type}_edited"
    edited_p = paths.get(edited_key)
    if edited_p and os.path.exists(edited_p):
        return FileResponse(edited_p, media_type="application/msword", filename=os.path.basename(edited_p))
    # –ò–Ω–∞—á–µ ‚Äî –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π .docx –∏–∑ —à–∞–±–ª–æ–Ω–∞
    p = paths.get(doc_type)
    if not p or not os.path.exists(p): raise HTTPException(404)
    return FileResponse(p, media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document", filename=os.path.basename(p))

@app.get("/api/preview/{task_id}/{doc_type}")
async def preview_html(task_id: str, doc_type: str):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç .docx ‚Üí HTML –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ä–µ–¥–∞–∫—Ç–æ—Ä–µ."""
    p = file_paths.get(task_id, {}).get(doc_type)
    if not p or not os.path.exists(p):
        raise HTTPException(404, f"File not found: {doc_type}")
    try:
        import mammoth
        with open(p, "rb") as f:
            result = mammoth.convert_to_html(f)
        html = result.value
        # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—ã–µ —Å—Ç–∏–ª–∏
        styled = f"""<style>
body {{ font-family: 'Segoe UI', Arial, sans-serif; font-size: 14px; line-height: 1.6; color: #1a1a2e; padding: 20px; }}
h1 {{ font-size: 20px; color: #1a1a2e; border-bottom: 2px solid #4361ee; padding-bottom: 8px; }}
h2 {{ font-size: 16px; color: #3a3a5c; margin-top: 24px; }}
h3 {{ font-size: 14px; color: #4361ee; }}
table {{ width: 100%; border-collapse: collapse; margin: 12px 0; }}
th, td {{ border: 1px solid #ddd; padding: 8px 10px; text-align: left; font-size: 13px; }}
th {{ background: #f0f2ff; font-weight: 600; }}
tr:nth-child(even) {{ background: #fafbff; }}
p {{ margin: 6px 0; }}
strong {{ color: #1a1a2e; }}
</style>
{html}"""
        return {"html": styled, "messages": result.messages}
    except Exception as e:
        raise HTTPException(500, f"Conversion error: {e}")

@app.put("/api/save/{task_id}/{doc_type}")
async def save_html(task_id: str, doc_type: str, body: dict):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π HTML —Ä—è–¥–æ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º .docx (–Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—è –µ–≥–æ)."""
    p = file_paths.get(task_id, {}).get(doc_type)
    if not p:
        raise HTTPException(404, "File not found")
    html_content = body.get("html", "")
    if not html_content:
        raise HTTPException(400, "Empty HTML")
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML-–≤–µ—Ä—Å–∏—é —Ä—è–¥–æ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π .docx –∏–∑ —à–∞–±–ª–æ–Ω–∞ –ù–ï —Ç—Ä–æ–≥–∞–µ–º)
    edited_path = p.replace(".docx", "_edited.doc")
    # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ Word-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π HTML (Word –æ—Ç–∫—Ä–æ–µ—Ç .doc —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
    import re
    clean_html = re.sub(r'<style[^>]*>.*?</style>', '', html_content, flags=re.DOTALL)
    # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º ¬´–°–ò–ù–û–ü–°–ò–° –ü–†–û–¢–û–ö–û–õ–ê¬ª ‚Äî –∏—â–µ–º –ª—é–±–æ–π —Ç–µ–≥, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç
    # –∏ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤—Å—é —Å—Ç—Ä–æ–∫—É –≤ <center> (—Å–∞–º—ã–π –Ω–∞–¥—ë–∂–Ω—ã–π —Å–ø–æ—Å–æ–± –¥–ª—è Word)
    clean_html = re.sub(
        r'<p[^>]*>.*?–°–ò–ù–û–ü–°–ò–°\s+–ü–†–û–¢–û–ö–û–õ–ê.*?</p>',
        '<center><p><b>–°–ò–ù–û–ü–°–ò–° –ü–†–û–¢–û–ö–û–õ–ê</b></p></center>',
        clean_html,
        flags=re.IGNORECASE | re.DOTALL
    )
    # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    print(f"  üìù save_html: first 300 chars of clean_html: {clean_html[:300]}")
    word_html = f'''<html xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns="http://www.w3.org/TR/REC-html40">
<head><meta charset="utf-8">
<!--[if gte mso 9]><xml><w:WordDocument><w:View>Print</w:View></w:WordDocument></xml><![endif]-->
<style>
body {{ font-family: 'Times New Roman', serif; font-size: 12pt; line-height: 1.5; }}
table {{ width: 100%; border-collapse: collapse; }}
td, th {{ border: 1px solid #000; padding: 4pt 6pt; vertical-align: top; font-size: 12pt; }}
th {{ background: #f0f2ff; font-weight: bold; }}
p {{ margin: 3pt 0; font-size: 12pt; }}
h1, h2, h3 {{ text-align: center; font-size: 14pt; }}
</style>
</head>
<body>{clean_html}</body></html>'''
    with open(edited_path, "w", encoding="utf-8") as f:
        f.write(word_html)
    # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –ø—É—Ç—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏
    if task_id not in file_paths:
        file_paths[task_id] = {}
    file_paths[task_id][f"{doc_type}_edited"] = edited_path
    return {"ok": True, "path": edited_path}

@app.get("/api/history", response_model=List[HistoryItem])
async def get_history(): return history[:50]

@app.delete("/api/history/{task_id}")
async def del_history(task_id: str):
    global history; history = [h for h in history if h.task_id != task_id]; return {"ok": True}

@app.post("/api/chat")
async def chat(message: str = "", task_id: str = ""):
    return {"reply": "–ü–æ–Ω—è–ª, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é."}

# ‚ïê‚ïê‚ïê Dictionaries (–ø–æ–¥—Å–∫–∞–∑–∫–∏, –ë–ï–ó –≤–∞–ª–∏–¥–∞—Ü–∏–∏) ‚ïê‚ïê‚ïê
_INN = [
    {"ru":"–ê–º–ª–æ–¥–∏–ø–∏–Ω","en":"Amlodipine"},{"ru":"–ê—Ç–æ—Ä–≤–∞—Å—Ç–∞—Ç–∏–Ω","en":"Atorvastatin"},
    {"ru":"–ê–º–æ–∫—Å–∏—Ü–∏–ª–ª–∏–Ω","en":"Amoxicillin"},{"ru":"–ú–µ—Ç—Ñ–æ—Ä–º–∏–Ω","en":"Metformin"},
    {"ru":"–õ–µ–≤–æ—Ñ–ª–æ–∫—Å–∞—Ü–∏–Ω","en":"Levofloxacin"},{"ru":"–û–º–µ–ø—Ä–∞–∑–æ–ª","en":"Omeprazole"},
    {"ru":"–õ–∏–∑–∏–Ω–æ–ø—Ä–∏–ª","en":"Lisinopril"},{"ru":"–†–æ–∑—É–≤–∞—Å—Ç–∞—Ç–∏–Ω","en":"Rosuvastatin"},
    {"ru":"–ö–ª–∞—Ä–∏—Ç—Ä–æ–º–∏—Ü–∏–Ω","en":"Clarithromycin"},{"ru":"–î–∏–∫–ª–æ—Ñ–µ–Ω–∞–∫","en":"Diclofenac"},
    {"ru":"–ò–±—É–ø—Ä–æ—Ñ–µ–Ω","en":"Ibuprofen"},{"ru":"–°–∏–ª–¥–µ–Ω–∞—Ñ–∏–ª","en":"Sildenafil"},
    {"ru":"–í–∞—Ä—Ñ–∞—Ä–∏–Ω","en":"Warfarin"},{"ru":"–ü–∞—Ä–∞—Ü–µ—Ç–∞–º–æ–ª","en":"Paracetamol"},
    {"ru":"–≠–Ω–∞–ª–∞–ø—Ä–∏–ª","en":"Enalapril"},{"ru":"–õ–æ—Ä–∞—Ç–∞–¥–∏–Ω","en":"Loratadine"},
    {"ru":"–í–∞–ª—Å–∞—Ä—Ç–∞–Ω","en":"Valsartan"},{"ru":"–¢–∞–º—Å—É–ª–æ–∑–∏–Ω","en":"Tamsulosin"},
    {"ru":"–¢–µ–Ω–æ—Ñ–æ–≤–∏—Ä–∞ –∞–ª–∞—Ñ–µ–Ω–∞–º–∏–¥","en":"Tenofovir alafenamide"},
    {"ru":"–≠–º—Ç—Ä–∏—Ü–∏—Ç–∞–±–∏–Ω","en":"Emtricitabine"},{"ru":"–ë–∏–∫—Ç–µ–≥—Ä–∞–≤–∏—Ä","en":"Bictegravir"},
    {"ru":"–±–∏–∫—Ç–µ–≥—Ä–∞–≤–∏—Ä + —Ç–µ–Ω–æ—Ñ–æ–≤–∏—Ä–∞ –∞–ª–∞—Ñ–µ–Ω–∞–º–∏–¥ + —ç–º—Ç—Ä–∏—Ü–∏—Ç–∞–±–∏–Ω","en":"Bictegravir + Tenofovir alafenamide + Emtricitabine"},
    {"ru":"–î–∞–ø–∞–≥–ª–∏—Ñ–ª–æ–∑–∏–Ω","en":"Dapagliflozin"},{"ru":"–≠–º–ø–∞–≥–ª–∏—Ñ–ª–æ–∑–∏–Ω","en":"Empagliflozin"},
    {"ru":"–ê–ø–∏–∫—Å–∞–±–∞–Ω","en":"Apixaban"},{"ru":"–†–∏–≤–∞—Ä–æ–∫—Å–∞–±–∞–Ω","en":"Rivaroxaban"},
    {"ru":"–¶–∏–ø—Ä–æ—Ñ–ª–æ–∫—Å–∞—Ü–∏–Ω","en":"Ciprofloxacin"},{"ru":"–¶–µ—Ñ—Ç—Ä–∏–∞–∫—Å–æ–Ω","en":"Ceftriaxone"},
    {"ru":"–ü—Ä–µ–≥–∞–±–∞–ª–∏–Ω","en":"Pregabalin"},{"ru":"–î—É–ª–æ–∫—Å–µ—Ç–∏–Ω","en":"Duloxetine"},
]


# ‚ïê‚ïê‚ïê –ì–ª–æ–±–∞–ª—å–Ω–∞—è HTTP-—Å–µ—Å—Å–∏—è (–ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–µ —Å–æ–∑–¥–∞—ë—Ç—Å—è –∫–∞–∂–¥—ã–π —Ä–∞–∑) ‚ïê‚ïê‚ïê

import aiohttp, urllib.parse

_http_session: aiohttp.ClientSession | None = None
_TIMEOUT = aiohttp.ClientTimeout(total=2)
_HEADERS = {"User-Agent": "Mozilla/5.0"}

async def _get_session() -> aiohttp.ClientSession:
    global _http_session
    if _http_session is None or _http_session.closed:
        _http_session = aiohttp.ClientSession(timeout=_TIMEOUT, headers=_HEADERS)
    return _http_session

@app.on_event("shutdown")
async def _close_session():
    global _http_session
    if _http_session and not _http_session.closed:
        await _http_session.close()


# ‚ïê‚ïê‚ïê Yandex Suggest ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ‚ïê‚ïê‚ïê

async def _yandex_suggest(query: str, suffix: str = "", clean_fn=None) -> list[str]:
    """–ü–æ–¥—Å–∫–∞–∑–∫–∏ —á–µ—Ä–µ–∑ Yandex Suggest API (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π, –±–µ–∑ –∫–ª—é—á–∞)."""
    search_q = f"{query} {suffix}".strip() if suffix else query
    url = f"https://suggest.yandex.ru/suggest-ff.cgi?part={urllib.parse.quote(search_q)}&uil=ru&n=10"
    results = []
    try:
        session = await _get_session()
        async with session.get(url) as resp:
            if resp.status == 200:
                data = await resp.json(content_type=None)
                if isinstance(data, list) and len(data) >= 2:
                    for s in data[1]:
                        clean = clean_fn(s) if clean_fn else s.strip()
                        if clean and len(clean) >= 2:
                            results.append(clean)
    except Exception:
        pass
    return results


def _clean_inn(text: str) -> str:
    import re
    text = re.sub(
        r'\s+(–º–Ω–Ω|–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è|–ø–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é|—Ç–∞–±–ª–µ—Ç–∫–∏|–∫–∞–ø—Å—É–ª—ã|–ø—Ä–µ–ø–∞—Ä–∞—Ç|–∞–Ω–∞–ª–æ–≥–∏|—Ü–µ–Ω–∞|–æ—Ç–∑—ã–≤—ã|'
        r'–ø–æ–±–æ—á–Ω—ã–µ|–¥–µ–π—Å—Ç–≤–∏—è|–ø–æ–∫–∞–∑–∞–Ω–∏—è|—Å–æ—Å—Ç–∞–≤|–¥–æ–∑–∏—Ä–æ–≤–∫–∞|—Ä–µ—Ü–µ–ø—Ç|–∫—É–ø–∏—Ç—å|–∞–ø—Ç–µ–∫–∞).*$',
        '', text.strip(), flags=re.IGNORECASE)
    text = re.sub(r'\s+', ' ', text).strip()
    return text[0].upper() + text[1:] if text else ""


def _clean_form(text: str) -> str:
    import re
    text = re.sub(
        r'\s+(—ç—Ç–æ|—á—Ç–æ —Ç–∞–∫–æ–µ|–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è|–ø—Ä–µ–ø–∞—Ä–∞—Ç|–ª–µ–∫–∞—Ä—Å—Ç–≤–æ|–ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞|–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ|'
        r'–≤–∏–¥—ã|–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è|–ø—Ä–∏–º–µ—Ä—ã|—Å–ø–∏—Å–æ–∫|—Ñ–æ—Ç–æ|–∫—É–ø–∏—Ç—å).*$',
        '', text.strip(), flags=re.IGNORECASE)
    return re.sub(r'\s+', ' ', text).strip().lower()


def _clean_company(text: str) -> str:
    import re
    text = re.sub(
        r'\s+(–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç|–æ—Ç–∑—ã–≤—ã|–≤–∞–∫–∞–Ω—Å–∏–∏|–∞–¥—Ä–µ—Å|—Ç–µ–ª–µ—Ñ–æ–Ω|–∏–Ω–Ω|–æ–≥—Ä–Ω|—Ä–µ–∫–≤–∏–∑–∏—Ç—ã|–ø—Ä–æ–¥—É–∫—Ü–∏—è|'
        r'—Å–∞–π—Ç|wiki|wikipedia|–∫–æ–Ω—Ç–∞–∫—Ç—ã|—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ|–ª–∏—Ü–µ–Ω–∑–∏—è|–∏—Å—Ç–æ—Ä–∏—è).*$',
        '', text.strip(), flags=re.IGNORECASE)
    return re.sub(r'\s+', ' ', text).strip()


def _clean_drug(text: str) -> str:
    import re
    original = text.strip()
    # –£–±–∏—Ä–∞–µ–º —Ö–≤–æ—Å—Ç—ã: "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "—Ü–µ–Ω–∞", "–∞–Ω–∞–ª–æ–≥–∏" –∏ —Ç.–¥.
    text = re.sub(
        r'\s+(–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è|–ø–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é|—Ü–µ–Ω–∞|–∞–Ω–∞–ª–æ–≥–∏|–æ—Ç–∑—ã–≤—ã|–ø–æ–±–æ—á–Ω—ã–µ|–ø–æ–∫–∞–∑–∞–Ω–∏—è|—Å–æ—Å—Ç–∞–≤|'
        r'–∫—É–ø–∏—Ç—å|–∞–ø—Ç–µ–∫–∞|—Ä–µ—Ü–µ–ø—Ç|–¥–æ–∑–∏—Ä–æ–≤–∫–∞|–¥–ª—è —á–µ–≥–æ|–ø–æ–±–æ—á–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è|–æ—Ç–ª–∏—á–∏–µ|'
        r'–∏ \w+|–∏–ª–∏ \w+|—á—Ç–æ –ª—É—á—à–µ|—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ|–∑–∞–º–µ–Ω–∞|–≤–º–µ—Å—Ç–æ).*$',
        '', original, flags=re.IGNORECASE)
    # –£–±–∏—Ä–∞–µ–º "—Ç–∞–±–ª–µ—Ç–∫–∏", "–∫–∞–ø—Å—É–ª—ã" –≤ –∫–æ–Ω—Ü–µ
    text = re.sub(r'\s+(—Ç–∞–±–ª–µ—Ç–∫–∏|–∫–∞–ø—Å—É–ª—ã|—Ä–∞—Å—Ç–≤–æ—Ä|–º–∞–∑—å|–≥–µ–ª—å|–∫—Ä–µ–º|—Å–∏—Ä–æ–ø)$', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\s+', ' ', text).strip()
    return text[0].upper() + text[1:] if text else ""


def _extract_trade_name(text: str, inn: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ—Ä–≥–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ, —É–±–∏—Ä–∞—è –ú–ù–ù –∏–∑ —Å—Ç—Ä–æ–∫–∏."""
    if not inn:
        return text
    # –£–±–∏—Ä–∞–µ–º –ú–ù–ù –∏–∑ —Å—Ç—Ä–æ–∫–∏ (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ)
    import re
    cleaned = re.sub(re.escape(inn), '', text, flags=re.IGNORECASE).strip()
    # –£–±–∏—Ä–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø—Ä–æ–±–µ–ª—ã –∏ –º—É—Å–æ—Ä
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    cleaned = re.sub(r'^[\s\-\+\¬∑,]+|[\s\-\+\¬∑,]+$', '', cleaned)
    if cleaned and len(cleaned) >= 2:
        return cleaned[0].upper() + cleaned[1:]
    return text  # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –ú–ù–ù –Ω–∏—á–µ–≥–æ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å


def _clean_excipient(text: str) -> str:
    import re
    text = re.sub(
        r'\s+(—á—Ç–æ —ç—Ç–æ|—ç—Ç–æ|–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ|—Å–≤–æ–π—Å—Ç–≤–∞|—Ñ–æ—Ä–º—É–ª–∞|–ø–∏—â–µ–≤–∞—è –¥–æ–±–∞–≤–∫–∞|–≤ —Ç–∞–±–ª–µ—Ç–∫–∞—Ö|'
        r'–≤—Ä–µ–¥|–ø–æ–ª—å–∑–∞|–æ–ø–∏—Å–∞–Ω–∏–µ|e\s*\d+|–∫—É–ø–∏—Ç—å|—Ü–µ–Ω–∞|–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ).*$',
        '', text.strip(), flags=re.IGNORECASE)
    return re.sub(r'\s+', ' ', text).strip().lower()


async def _suggest_and_merge_strings(q: str, local: list[str], suffix: str, clean_fn) -> list[str]:
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å Yandex Suggest –¥–ª—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö —Å–ø–∏—Å–∫–æ–≤."""
    if len(local) < 5 and len(q) >= 2:
        try:
            suggestions = await _yandex_suggest(q, suffix=suffix, clean_fn=clean_fn)
            local_lower = {x.lower() for x in local}
            for s in suggestions:
                if s.lower() not in local_lower and s.lower() != q.lower():
                    local.append(s)
                    local_lower.add(s.lower())
        except Exception as e:
            print(f"  ‚ö†Ô∏è Yandex Suggest error: {e}")
    return local[:10]


# ‚ïê‚ïê‚ïê DaData ‚Äî –ø–æ–∏—Å–∫ –∫–æ–º–ø–∞–Ω–∏–π ‚ïê‚ïê‚ïê

DADATA_TOKEN = os.getenv("DADATA_TOKEN", "")
print(f"  ‚ÑπÔ∏è DADATA_TOKEN: {'‚úÖ –∑–∞–≥—Ä—É–∂–µ–Ω (' + DADATA_TOKEN[:8] + '...)' if DADATA_TOKEN else '‚ùå –Ω–µ –∑–∞–¥–∞–Ω'}")
_YANDEX_FOLDER = os.getenv("YANDEX_FOLDER_ID", "")
_YANDEX_KEY = os.getenv("YANDEX_API_KEY", "")
print(f"  ‚ÑπÔ∏è YANDEX_FOLDER_ID: {'‚úÖ ' + _YANDEX_FOLDER[:8] + '...' if _YANDEX_FOLDER else '‚ùå –Ω–µ –∑–∞–¥–∞–Ω'}")
print(f"  ‚ÑπÔ∏è YANDEX_API_KEY: {'‚úÖ –∑–∞–≥—Ä—É–∂–µ–Ω' if _YANDEX_KEY else '‚ùå –Ω–µ –∑–∞–¥–∞–Ω'}")

async def _dadata_suggest_company(query: str, count: int = 10) -> list[dict]:
    """–ü–æ–∏—Å–∫ –∫–æ–º–ø–∞–Ω–∏–∏ —á–µ—Ä–µ–∑ DaData Suggestions API."""
    if not DADATA_TOKEN:
        print(f"  ‚ö†Ô∏è DaData: —Ç–æ–∫–µ–Ω –Ω–µ –∑–∞–¥–∞–Ω (DADATA_TOKEN –ø—É—Å—Ç–æ–π)")
        return []
    url = "https://suggestions.dadata.ru/suggestions/api/4_1/rs/suggest/party"
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "Authorization": f"Token {DADATA_TOKEN}",
    }
    payload = {"query": query, "count": count}
    try:
        async with aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=5)
        ) as dadata_session:
            async with dadata_session.post(url, json=payload, headers=headers) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    results = []
                    for s in data.get("suggestions", []):
                        d = s.get("data", {})
                        name_full = s.get("value", "")
                        inn = d.get("inn", "")
                        address = ""
                        if d.get("address"):
                            address = d["address"].get("value", "")
                        results.append({"name": name_full, "inn": inn, "address": address})
                    return results
                else:
                    body = await resp.text()
                    print(f"  ‚ö†Ô∏è DaData HTTP {resp.status}: {body[:200]}")
    except Exception as e:
        print(f"  ‚ö†Ô∏è DaData error: {type(e).__name__}: {e}")
    return []


async def _search_company_combined(q: str, kind: str = "") -> list[dict]:
    """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫: DaData (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ‚Üí Yandex Suggest (fallback)."""
    results = []
    if DADATA_TOKEN:
        dadata_results = await _dadata_suggest_company(q)
        for r in dadata_results:
            results.append({
                "name": r["name"], "inn": r.get("inn", ""),
                "address": r.get("address", ""), "source": "dadata",
            })
    if len(results) < 3:
        suffix_map = {
            "research_center": "–∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–π —Ü–µ–Ω—Ç—Ä –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
            "biolab": "–±–∏–æ–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è",
            "insurance": "—Å—Ç—Ä–∞—Ö–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏—è",
            "general": "–∫–æ–º–ø–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è",
        }
        suffix = suffix_map.get(kind, "–∫–æ–º–ø–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è")
        try:
            yandex = await _yandex_suggest(q, suffix=suffix, clean_fn=_clean_company)
            existing = {r["name"].lower() for r in results}
            for s in yandex:
                if s.lower() not in existing and len(s) >= 2:
                    results.append({"name": s, "inn": "", "address": "", "source": "yandex"})
                    existing.add(s.lower())
        except Exception:
            pass
    if not results:
        results = [{"name": q, "inn": "", "address": ""}]
    return results[:10]


# ‚ïê‚ïê‚ïê –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ ‚ïê‚ïê‚ïê

@app.get("/api/dictionaries/inn")
async def inn(q: str = ""):
    if not q: return _INN[:10]
    ql = q.lower()
    local = [d for d in _INN if ql in d["ru"].lower() or ql in d["en"].lower()]
    if len(q) >= 2:
        try:
            suggestions = await _yandex_suggest(q, suffix="–ú–ù–ù", clean_fn=_clean_inn)
            local_names = {d["ru"].lower() for d in local}
            for s in suggestions:
                if s.lower() not in local_names:
                    local.append({"ru": s, "en": "", "source": "yandex"})
                    local_names.add(s.lower())
        except Exception as e:
            print(f"  ‚ö†Ô∏è Yandex INN error: {e}")
    if not local: local = [{"ru": q, "en": "", "custom": True}]
    return local[:10]


@app.get("/api/dictionaries/forms")
async def forms(q: str = ""):
    _FORMS = [
        "—Ç–∞–±–ª–µ—Ç–∫–∏","—Ç–∞–±–ª–µ—Ç–∫–∏, –ø–æ–∫—Ä—ã—Ç—ã–µ –ø–ª—ë–Ω–æ—á–Ω–æ–π –æ–±–æ–ª–æ—á–∫–æ–π","—Ç–∞–±–ª–µ—Ç–∫–∏, –ø–æ–∫—Ä—ã—Ç—ã–µ –ø–ª–µ–Ω–æ—á–Ω–æ–π –æ–±–æ–ª–æ—á–∫–æ–π",
        "—Ç–∞–±–ª–µ—Ç–∫–∏, –ø–æ–∫—Ä—ã—Ç—ã–µ –æ–±–æ–ª–æ—á–∫–æ–π","—Ç–∞–±–ª–µ—Ç–∫–∏ –ø—Ä–æ–ª–æ–Ω–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è","—Ç–∞–±–ª–µ—Ç–∫–∏ –∂–µ–≤–∞—Ç–µ–ª—å–Ω—ã–µ",
        "—Ç–∞–±–ª–µ—Ç–∫–∏ –¥–∏—Å–ø–µ—Ä–≥–∏—Ä—É–µ–º—ã–µ","—Ç–∞–±–ª–µ—Ç–∫–∏ –¥–ª—è —Ä–∞—Å—Å–∞—Å—ã–≤–∞–Ω–∏—è","—Ç–∞–±–ª–µ—Ç–∫–∏ —Ä–∞—Å—Ç–≤–æ—Ä–∏–º—ã–µ",
        "—Ç–∞–±–ª–µ—Ç–∫–∏ —à–∏–ø—É—á–∏–µ","—Ç–∞–±–ª–µ—Ç–∫–∏ —Å—É–±–ª–∏–Ω–≥–≤–∞–ª—å–Ω—ã–µ","—Ç–∞–±–ª–µ—Ç–∫–∏ –±—É–∫–∫–∞–ª—å–Ω—ã–µ",
        "–∫–∞–ø—Å—É–ª—ã","–∫–∞–ø—Å—É–ª—ã —Ç–≤—ë—Ä–¥—ã–µ –∂–µ–ª–∞—Ç–∏–Ω–æ–≤—ã–µ","–∫–∞–ø—Å—É–ª—ã –º—è–≥–∫–∏–µ –∂–µ–ª–∞—Ç–∏–Ω–æ–≤—ã–µ",
        "–∫–∞–ø—Å—É–ª—ã –∫–∏—à–µ—á–Ω–æ—Ä–∞—Å—Ç–≤–æ—Ä–∏–º—ã–µ","–∫–∞–ø—Å—É–ª—ã —Å –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤—ã—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ–º",
        "—Ä–∞—Å—Ç–≤–æ—Ä –¥–ª—è –ø—Ä–∏—ë–º–∞ –≤–Ω—É—Ç—Ä—å","—Å—É—Å–ø–µ–Ω–∑–∏—è –¥–ª—è –ø—Ä–∏—ë–º–∞ –≤–Ω—É—Ç—Ä—å","—Å–∏—Ä–æ–ø","—ç–ª–∏–∫—Å–∏—Ä",
        "–∫–∞–ø–ª–∏ –¥–ª—è –ø—Ä–∏—ë–º–∞ –≤–Ω—É—Ç—Ä—å","–ø–æ—Ä–æ—à–æ–∫ –¥–ª—è –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è —Ä–∞—Å—Ç–≤–æ—Ä–∞ –¥–ª—è –ø—Ä–∏—ë–º–∞ –≤–Ω—É—Ç—Ä—å",
        "–≥—Ä–∞–Ω—É–ª—ã –¥–ª—è –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è —Å—É—Å–ø–µ–Ω–∑–∏–∏","–≥—Ä–∞–Ω—É–ª—ã","–ø–∞—Å—Ç–∏–ª–∫–∏","–ª–µ–¥–µ–Ω—Ü—ã",
        "–ø–æ—Ä–æ—à–æ–∫ –¥–ª—è –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è —Ä–∞—Å—Ç–≤–æ—Ä–∞ –¥–ª—è –∏–Ω—ä–µ–∫—Ü–∏–π",
        "–ª–∏–æ—Ñ–∏–ª–∏–∑–∞—Ç –¥–ª—è –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è —Ä–∞—Å—Ç–≤–æ—Ä–∞ –¥–ª—è –∏–Ω—ä–µ–∫—Ü–∏–π",
        "—Ä–∞—Å—Ç–≤–æ—Ä –¥–ª—è –≤–Ω—É—Ç—Ä–∏–≤–µ–Ω–Ω–æ–≥–æ –≤–≤–µ–¥–µ–Ω–∏—è","—Ä–∞—Å—Ç–≤–æ—Ä –¥–ª—è –≤–Ω—É—Ç—Ä–∏–º—ã—à–µ—á–Ω–æ–≥–æ –≤–≤–µ–¥–µ–Ω–∏—è",
        "—Ä–∞—Å—Ç–≤–æ—Ä –¥–ª—è –∏–Ω—ä–µ–∫—Ü–∏–π","—ç–º—É–ª—å—Å–∏—è –¥–ª—è –∏–Ω—Ñ—É–∑–∏–π","—Å—É—Å–ø–µ–Ω–∑–∏—è –¥–ª—è –∏–Ω—ä–µ–∫—Ü–∏–π",
        "–∫—Ä–µ–º","–º–∞–∑—å","–≥–µ–ª—å","–≥–µ–ª—å –¥–ª—è –Ω–∞—Ä—É–∂–Ω–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è","–ª–∏–Ω–∏–º–µ–Ω—Ç","–ø–∞—Å—Ç–∞",
        "—Ä–∞—Å—Ç–≤–æ—Ä –¥–ª—è –Ω–∞—Ä—É–∂–Ω–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è","—Å–ø—Ä–µ–π –¥–ª—è –Ω–∞—Ä—É–∂–Ω–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è",
        "—Å—É–ø–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ —Ä–µ–∫—Ç–∞–ª—å–Ω—ã–µ","—Å—É–ø–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –≤–∞–≥–∏–Ω–∞–ª—å–Ω—ã–µ",
        "—Å–ø—Ä–µ–π –Ω–∞–∑–∞–ª—å–Ω—ã–π","–∫–∞–ø–ª–∏ –Ω–∞–∑–∞–ª—å–Ω—ã–µ","–∫–∞–ø–ª–∏ –≥–ª–∞–∑–Ω—ã–µ","–º–∞–∑—å –≥–ª–∞–∑–Ω–∞—è","–≥–µ–ª—å –≥–ª–∞–∑–Ω–æ–π",
        "–∫–∞–ø–ª–∏ —É—à–Ω—ã–µ","—Ä–∞—Å—Ç–≤–æ—Ä –¥–ª—è –∏–Ω–≥–∞–ª—è—Ü–∏–π","–ø–æ—Ä–æ—à–æ–∫ –¥–ª—è –∏–Ω–≥–∞–ª—è—Ü–∏–π",
        "–∞—ç—Ä–æ–∑–æ–ª—å –¥–ª—è –∏–Ω–≥–∞–ª—è—Ü–∏–π –¥–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π","—Å–ø—Ä–µ–π –¥–ª—è –∏–Ω–≥–∞–ª—è—Ü–∏–π",
        "–ø–ª–∞—Å—Ç—ã—Ä—å —Ç—Ä–∞–Ω—Å–¥–µ—Ä–º–∞–ª—å–Ω—ã–π","–ø–ª—ë–Ω–∫–∞ –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω–∞—è",
    ]
    if q:
        ql = q.lower()
        local = [x for x in _FORMS if ql in x.lower()]
        return await _suggest_and_merge_strings(q, local, suffix="–ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞", clean_fn=_clean_form)
    return _FORMS


@app.get("/api/dictionaries/manufacturers")
async def mfg(q: str = ""):
    if not q: return []
    results = await _search_company_combined(q, kind="general")
    return [r["name"] for r in results]


@app.get("/api/dictionaries/company")
async def company_search(q: str = "", kind: str = ""):
    if not q: return []
    return await _search_company_combined(q, kind=kind)


@app.get("/api/dictionaries/reference")
async def refs(inn: str = "", q: str = ""):
    """–†–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω—ã–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç—ã –ø–æ –ú–ù–ù ‚Äî —á–µ—Ä–µ–∑ Yandex GenSearch (–ì–†–õ–°)."""
    import re
    if not q and not inn:
        return []

    search_term = (q or inn).strip()
    # –ú–∏–Ω–∏–º—É–º 4 —Å–∏–º–≤–æ–ª–∞ ‚Äî –Ω–µ —Ç—Ä–∞—Ç–∏–º GenSearch –Ω–∞ "–ø–∞", "–ø–∞–ª"
    if len(search_term) < 4:
        return []

    YANDEX_FOLDER_ID = os.getenv("YANDEX_FOLDER_ID", "")
    YANDEX_API_KEY = os.getenv("YANDEX_API_KEY", "")

    if not YANDEX_FOLDER_ID or not YANDEX_API_KEY:
        print("‚ö†Ô∏è  YANDEX_FOLDER_ID/YANDEX_API_KEY –Ω–µ –∑–∞–¥–∞–Ω—ã ‚Äî fallback –Ω–∞ Suggest")
        return await _refs_fallback_suggest(inn, q)

    query = (
        f"–ü–µ—Ä–µ—á–∏—Å–ª–∏ –≤—Å–µ —Ç–æ—Ä–≥–æ–≤—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤ —Å –ú–ù–ù ¬´{search_term}¬ª, "
        f"–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤ –†–æ—Å—Å–∏–∏ (–ì–†–õ–°). "
        f"–£–∫–∞–∂–∏ —Ç–æ–ª—å–∫–æ —Ç–æ—Ä–≥–æ–≤—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –±–µ–∑ –¥–æ–∑–∏—Ä–æ–≤–æ–∫ –∏ –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ–æ—Ä–º. "
        f"–ù–∞—á–Ω–∏ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ (—Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–æ–≥–æ) –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞."
    )

    body = {
        "messages": [{"content": query, "role": "ROLE_USER"}],
        "folderId": YANDEX_FOLDER_ID,
        "searchType": "SEARCH_TYPE_RU",
        "fixMisspell": True,
    }
    headers = {
        "Authorization": f"Api-Key {YANDEX_API_KEY}",
        "Content-Type": "application/json",
    }

    try:
        session = await _get_session()
        async with session.post(
            "https://searchapi.api.cloud.yandex.net/v2/gen/search",
            json=body, headers=headers, timeout=aiohttp.ClientTimeout(total=15)
        ) as resp:
            if resp.status != 200:
                print(f"‚ùå Yandex GenSearch reference: HTTP {resp.status}")
                return await _refs_fallback_suggest(inn, q)
            data = await resp.json(content_type=None)
    except Exception as e:
        print(f"‚ùå Yandex GenSearch reference error: {e}")
        return await _refs_fallback_suggest(inn, q)

    # GenSearch –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –º–∞—Å—Å–∏–≤
    if isinstance(data, list):
        data = data[0] if data else {}

    answer_text = ""
    try:
        message = data.get("message", {})
        if isinstance(message, list):
            message = message[0] if message else {}
        if isinstance(message, dict):
            answer_text = message.get("content", "")
        if isinstance(answer_text, list):
            parts = []
            for item in answer_text:
                if isinstance(item, dict):
                    parts.append(str(item.get("content", item.get("text", ""))))
                elif isinstance(item, str):
                    parts.append(item)
            answer_text = " ".join(parts)
    except Exception:
        answer_text = str(data)[:500]

    if not answer_text:
        return await _refs_fallback_suggest(inn, q)

    print(f"üìã GenSearch reference ({search_term}): {answer_text[:200]}")

    # –ü–∞—Ä—Å–∏–º —Ç–æ—Ä–≥–æ–≤—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞
    # pre_clean: —É–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ markdown bold –∏ —Å–Ω–æ—Å–∫–∏, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–≤—ã—á–∫–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
    pre_clean = answer_text.replace("**", "").strip()
    pre_clean = re.sub(r'\[\d+\]', '', pre_clean)

    # clean: –ø–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–ª—è fallback-–ø–∞—Ä—Å–∏–Ω–≥–∞
    clean = re.sub(r'\([^)]*\)', '', pre_clean)
    clean = re.sub(r'[¬Æ‚Ñ¢¬´¬ª‚Äû"""\*]', '', clean)

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞ GenSearch
    names = []
    inn_lower = (inn or q or "").lower()

    # –ú—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞
    _GARBAGE = {
        "–ø—Ä–µ–ø–∞—Ä–∞—Ç", "–ª–µ–∫–∞—Ä—Å—Ç–≤–æ", "—Ç–∞–±–ª–µ—Ç–∫–∏", "–∫–∞–ø—Å—É–ª—ã", "–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π", "–∞–Ω–∞–ª–æ–≥–∏",
        "—Ç–æ—Ä–≥–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ", "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "—Ü–µ–Ω–∞", "–∫—É–ø–∏—Ç—å", "–æ—Ç–∑—ã–≤—ã", "—Å–æ—Å—Ç–∞–≤",
        "—ç—Ç–æ", "—ç—Ç–æ —Ö–∏–º–∏—è", "—Ö–∏–º–∏—è", "—Ñ–æ—Ä–º—É–ª–∞", "–¥–µ–π—Å—Ç–≤–∏–µ", "–º–µ—Ö–∞–Ω–∏–∑–º",
        "–ø–æ–±–æ—á–Ω—ã–µ", "–ø–æ–∫–∞–∑–∞–Ω–∏—è", "–ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è", "–¥–æ–∑–∏—Ä–æ–≤–∫–∞", "–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ",
        "–∏ –¥—Ä—É–≥–∏–µ", "–¥—Ä—É–≥–∏–µ", "—Ç–∞–∫–∂–µ", "–Ω–∞–ø—Ä–∏–º–µ—Ä", "–≤–∫–ª—é—á–∞—è", "–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ",
    }

    def _extract_name(text: str) -> str | None:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ—Ä–≥–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Å—Ç—Ä–æ–∫–∏ GenSearch."""
        # –£–±–∏—Ä–∞–µ–º markdown –∏ —Å–Ω–æ—Å–∫–∏
        text = re.sub(r'\[\d+\]', '', text)
        text = text.replace("**", "").strip()
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –≤ –∫–∞–≤—ã—á–∫–∞—Ö ‚Äî —Å–∞–º—ã–π –Ω–∞–¥—ë–∂–Ω—ã–π —Å–ø–æ—Å–æ–±
        m = re.search(r'[¬´"‚Äû]([^¬ª""]+)[¬ª""]', text)
        if m:
            return m.group(1).strip()
        # –£–±–∏—Ä–∞–µ–º —Å–∫–æ–±–∫–∏ —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º
        text = re.sub(r'\([^)]*\)', '', text)
        text = re.sub(r'[¬Æ‚Ñ¢¬´¬ª‚Äû"""\*]', '', text)
        # –£–±–∏—Ä–∞–µ–º –≤—Å—ë –ø–æ—Å–ª–µ —Ç–∏—Ä–µ (‚Äî –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å, –æ–ø–∏—Å–∞–Ω–∏–µ)
        text = re.split(r'\s*[‚Äî‚Äì-]\s', text)[0].strip()
        # –£–±–∏—Ä–∞–µ–º –≤–≤–æ–¥–Ω—ã–µ "–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π:", "–†–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω—ã–π:" –∏ —Ç.–¥.
        text = re.sub(r'^(–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω\w*|—Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω\w*|–≥–µ–Ω–µ—Ä–∏–∫\w*)\s*:\s*', '', text, flags=re.IGNORECASE)
        text = text.strip().strip('.,;:')
        return text if text and len(text) >= 2 else None

    def _is_valid(name: str) -> bool:
        nl = name.lower().strip()
        if not nl or len(nl) < 2 or len(nl) > 40:
            return False
        if nl == inn_lower or nl in _GARBAGE:
            return False
        if len(nl.split()) > 3:
            return False
        if re.match(r'^[\d\s,.\+/]+\s*(–º–≥|–º–∫–≥|–≥|–º–ª|%|–º–µ|–µ–¥)?$', nl):
            return False
        if any(w in nl for w in ['—è–≤–ª—è–µ—Ç—Å—è', '–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω', '–≤—ã–ø—É—Å–∫–∞–µ—Ç—Å—è', '—Å–æ–¥–µ—Ä–∂–∏—Ç', '–ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è', '—Ç–æ—Ä–≥–æ–≤—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è']):
            return False
        return True

    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º (markdown —Å–ø–∏—Å–∫–∏ * –∏–ª–∏ 1. 2. 3.)
    lines = pre_clean.split('\n')
    for line in lines:
        line = line.strip().lstrip('*‚Ä¢-‚Äì ').strip()
        if not line:
            continue
        extracted = _extract_name(line)
        if extracted and _is_valid(extracted):
            names.append(extracted)

    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∏ –Ω–µ –¥–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∑–∞–ø—è—Ç–æ–π –∏–∑ clean
    if not names:
        text_for_parse = re.sub(
            r'^.*?(—Ç–æ—Ä–≥–æ–≤—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è|–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã|–ø—Ä–µ–ø–∞—Ä–∞—Ç—ã)\s*[:‚Äî‚Äì-]\s*',
            '', clean, count=1, flags=re.IGNORECASE
        )
        candidates = re.split(r'[,;]\s*|\d+[.)]\s*', text_for_parse)
        for c in candidates:
            extracted = _extract_name(c)
            if extracted and _is_valid(extracted):
                names.append(extracted)

    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
    seen = set()
    result = []
    for name in names:
        nl = name.lower()
        if nl not in seen:
            seen.add(nl)
            result.append({"name": name, "inn": inn or "", "mfg": "", "source": "yandex_gensearch"})

    if not result:
        # –ï—Å–ª–∏ GenSearch –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ‚Äî fallback
        return await _refs_fallback_suggest(inn, q)

    return result[:10]


async def _refs_fallback_suggest(inn: str, q: str):
    """Fallback: –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Yandex Suggest (–º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–π)."""
    import re
    search_term = q or inn
    inn_lower = (inn or q or "").lower()
    seen = set()
    result = []

    def _extract(text):
        text = re.sub(
            r'\s+(–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è|–ø–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é|—Ü–µ–Ω–∞|–∞–Ω–∞–ª–æ–≥–∏|–æ—Ç–∑—ã–≤—ã|—Ç–∞–±–ª–µ—Ç–∫–∏|–∫–∞–ø—Å—É–ª—ã|'
            r'–∫—É–ø–∏—Ç—å|–ø—Ä–µ–ø–∞—Ä–∞—Ç|–ª–µ–∫–∞—Ä—Å—Ç–≤–æ|–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π|—Ç–æ—Ä–≥–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ|—ç—Ç–æ|—á—Ç–æ —ç—Ç–æ).*$',
            '', text.strip(), flags=re.IGNORECASE)
        text = re.sub(r'\s+', ' ', text).strip()
        if inn_lower:
            text_low = text.lower()
            if text_low.startswith(inn_lower):
                remainder = text[len(inn_lower):].strip()
                return remainder[0].upper() + remainder[1:] if remainder else ""
        return text[0].upper() + text[1:] if text else ""

    for suffix in ["—Ç–æ—Ä–≥–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ", "–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–µ–ø–∞—Ä–∞—Ç"]:
        if len(result) >= 5:
            break
        try:
            suggestions = await _yandex_suggest(search_term, suffix=suffix, clean_fn=_extract)
            for s in suggestions:
                sl = s.lower()
                if sl not in seen and len(s) >= 3 and sl != inn_lower and len(sl.split()) <= 3:
                    if not re.match(r'^[\d\s,.\+/]+\s*(–º–≥|–º–∫–≥|–≥|–º–ª|%)?$', sl):
                        result.append({"name": s, "inn": inn or "", "mfg": "", "source": "yandex"})
                        seen.add(sl)
        except Exception:
            pass

    return result[:10]


@app.get("/api/dictionaries/excipients")
async def exc(q: str = ""):
    if not q: return []
    try:
        suggestions = await _yandex_suggest(q, suffix="–≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–æ–µ –≤–µ—â–µ—Å—Ç–≤–æ —Ñ–∞—Ä–º–∞—Ü–µ–≤—Ç–∏–∫–∞", clean_fn=_clean_excipient)
        seen = set()
        result = []
        for s in suggestions:
            if s.lower() not in seen and len(s) >= 2:
                result.append(s)
                seen.add(s.lower())
        return result[:10] if result else [q]
    except Exception:
        return [q]


@app.get("/api/health")
async def health():
    return {"status": "ok", "llm": os.getenv("LLM_PROVIDER","mock"), "time": datetime.now().isoformat()}